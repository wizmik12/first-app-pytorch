{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfcd4a20",
   "metadata": {},
   "source": [
    "## Pytorch Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4d25df",
   "metadata": {},
   "source": [
    "### Crear nuevos tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac0d32f",
   "metadata": {},
   "source": [
    "Pytorch maneja y guarda la información en los llamados **tensores** de Pytorch. Los tensores son una generalización de los vectoes y matrices a arrays multidimensionales. Operar con tensores de Pytorch es muy similar a operar con tensores de numpy. De esta forma, veremos que muchas operaciones o formas de trabajar se pueden realizar de la misma manera aquí."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95c4eab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch # Importamos el módulo de Pytorch\n",
    "ones = torch.ones(5) # Creamos un vector de 5 componentes cuyo valor es '1'\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f943799f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de ceros: \n",
      " tensor([[0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0.]])\n",
      "Nueva matriz: \n",
      " tensor([[1., 2., 3., 4., 5.],\n",
      "        [1., 2., 3., 4., 5.],\n",
      "        [1., 2., 3., 4., 5.],\n",
      "        [1., 2., 3., 4., 5.],\n",
      "        [1., 2., 3., 4., 5.]])\n"
     ]
    }
   ],
   "source": [
    "zeros = torch.zeros((5,5)) # Un vector/matriz de '0' puede ser una forma adecuada de inicialización\n",
    "print(\"Matriz de ceros: \\n\", zeros)\n",
    "\n",
    "# Construimos una matriz por columnas a partir de esta matriz de ceros\n",
    "for i in range(len(zeros)):\n",
    "    zeros[:,i] = i + 1\n",
    "\n",
    "print(\"Nueva matriz: \\n\", zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1396310",
   "metadata": {},
   "source": [
    "También podemos crear un tensor de Pytorch a partir de una lista (o de un array de numpy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b5ecebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 3., 5., 2., 9., 0.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista = [1.0, 3.0, 5.0, 2.0, 9.0, 0.0]\n",
    "lista = torch.tensor(lista)\n",
    "lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5256edd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 3., 5.],\n",
       "        [2., 9., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista = [[1.0, 3.0, 5.0], [2.0, 9.0, 0.0]] # Podemos añadirle dimensiones\n",
    "lista = torch.tensor(lista)\n",
    "lista"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d865dd6e",
   "metadata": {},
   "source": [
    "### Indexación de tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a05ae0",
   "metadata": {},
   "source": [
    "Podemos usar la misma indexación que en Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a20c9235",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "some_list = torch.tensor((list(range(6))))\n",
    "some_list[:]     # <1>\n",
    "some_list[1:4]   # <2>\n",
    "some_list[1:]    # <3>\n",
    "some_list[:4]    # <4>\n",
    "some_list[:-1]   # <5>\n",
    "some_list[1:4:2] # <6>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c0ca2c",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">añadir forma avanzada de tensor del capitulo 4</span>.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8918ca2",
   "metadata": {},
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac300737",
   "metadata": {},
   "source": [
    "Podemos operar con tensores aunque no tengan la misma dimensión **<span style=\"color:red\">profundizar?</span>.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5bd932e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5, 12],\n",
       "        [21, 32]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix = torch.tensor([[1, 2], [3, 4]])\n",
    "matrix2 = torch.tensor([[5, 6], [7, 8]])\n",
    "matrix * matrix2 # producto elemento a elemento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "adc2c472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[19, 22],\n",
       "        [43, 50]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mm(matrix, matrix2) # producto matricial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a72f2630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [6, 8]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector = torch.tensor([1, 2]) # producto elemento a elemento en una dimension\n",
    "vector = vector.unsqueeze(-1)\n",
    "matrix * vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2d00a09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 2]), torch.Size([2, 1]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix.shape, vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4d3ef4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 4],\n",
       "        [3, 8]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix * vector.view(1, 2) # Usamos view para hacer un 'reshape'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861e644b",
   "metadata": {},
   "source": [
    "### Tipos de elementos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b959e2",
   "metadata": {},
   "source": [
    "En Pytorch tenemos distintos tipos de elementos para representar: enteros, punto flotantes, etc.\n",
    "En el caso de las redes neuronales, se suele usar **float32**, tiene menos precisión que 64-bit pero ganamos en memoria sin un fuerte impacto en la precisión del modelo. Pytorch espera que el indexado se haga con tensores **int64**. Además para indicar si algo está o no presente (booleano) se utilizará el tipo **bool**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21e4218",
   "metadata": {},
   "source": [
    "- torch.float32 o torch.float\n",
    "- torch.float64 o torch.double\n",
    "- torch.float16 o torch.half\n",
    "- torch.int8\n",
    "- torch.uint8\n",
    "- torch.int16 o torch.short\n",
    "- torch.int32 o torch.int\n",
    "- torch.int64 o torch.long\n",
    "- torch.bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "33d85c9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.int64, torch.float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector1 = torch.tensor([1, 1, 1])\n",
    "vector2 = torch.tensor([1.0, 1.0, 1.0])\n",
    "vector1.dtype, vector2.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8172e635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector1 = torch.tensor([1, 1, 1], dtype=torch.float64)\n",
    "vector1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b7cc5458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([True, True, True]), torch.bool)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector1 = torch.tensor([1, 1, 1], dtype=torch.bool)\n",
    "vector1, vector1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "76e35abf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2313, -1.1728, -0.6453],\n",
       "        [-1.3283, -0.4990,  0.7516],\n",
       "        [-1.5333,  0.6149, -0.8768]], dtype=torch.float64)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_vector = torch.randn(3, 3).to(torch.double)\n",
    "random_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5e2bba",
   "metadata": {},
   "source": [
    "### Copia de tensores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "73d9954e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector1 = torch.tensor([1, 2])\n",
    "vector2 = vector1\n",
    "vector2[0] = 0\n",
    "vector1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "b762206a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector1 = torch.tensor([1, 2])\n",
    "vector2 = vector1.clone()\n",
    "vector2[0] = 0\n",
    "vector1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde0f889",
   "metadata": {},
   "source": [
    "Vectores contiguos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1025ec",
   "metadata": {},
   "source": [
    "### Tensor API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695ff626",
   "metadata": {},
   "source": [
    "Vamos a ver las distintas operaciones que se pueden hacer con tensores. La gran mayoría está disponible en el módulo de torch por lo que pueden ser llamadas como métodos de un objeto tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8fa680db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4]), torch.Size([4, 3]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3, 4)\n",
    "a_t = torch.transpose(a, 0, 1) # damos las dimensiones que queremos intercambiar\n",
    "a.shape, a_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "77b8aaa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 4]), torch.Size([4, 3]))"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3, 4)\n",
    "a_t = a.transpose(0,1) # usamos el método del vector (pueden usarse indistinguiblemente)\n",
    "a.shape, a_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810e3238",
   "metadata": {},
   "source": [
    "### Guardar los tensores en CPU y GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ac6e5f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3, 4]), tensor([3, 4], device='cuda:0'))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_vector = torch.tensor([3, 4], device = 'cpu')\n",
    "gpu_vector = torch.tensor([3, 4], device = 'cuda')\n",
    "cpu_vector, gpu_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b39679dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 4], device='cuda:0')"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_vector.to(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "1559c299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3, 4]), tensor([3, 4], device='cuda:0'))"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpu_vector.cpu(), cpu_vector.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "01f8439c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 4.], device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cpu_vector.to(device = 'cuda', dtype = torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2c029698",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10105/4031067957.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcpu_vector\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgpu_vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "cpu_vector + gpu_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5aeed71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6, 8], device='cuda:0')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suma_gpu = cpu_vector.cuda() + gpu_vector\n",
    "suma_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "98548cf2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10105/163724389.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msuma_gpu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "suma_gpu.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "513f5800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 8])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suma_gpu.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54437b97",
   "metadata": {},
   "source": [
    "### Avanzado: Contiguos y dónde están"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553fb258",
   "metadata": {},
   "source": [
    "Los tensores contiguos son aquellos tensores que pueden ser recorridos sin dar saltos en memoria. Esto ayuda a la eficiencia de los algoritmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7f3bd07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(3, 2)\n",
    "a_t = a.transpose(0, 1)\n",
    "a.is_contiguous(), a_t.is_contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9927df",
   "metadata": {},
   "source": [
    "Algunas funciones necesitan que el vector sea contiguo. Para ello podemos utilizar el método .contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f203a371",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10105/3565261750.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: view size is not compatible with input tensor's size and stride (at least one dimension spans across two contiguous subspaces). Use .reshape(...) instead."
     ]
    }
   ],
   "source": [
    "a_t.view(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b36c7dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_t.contiguous().view(3, 2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2e2c9d",
   "metadata": {},
   "source": [
    "### Ejercicios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed6dd7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
