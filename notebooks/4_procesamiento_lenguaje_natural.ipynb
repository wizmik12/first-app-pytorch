{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30a9864b",
   "metadata": {
    "id": "30a9864b"
   },
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050bff79",
   "metadata": {
    "id": "050bff79"
   },
   "source": [
    "## Datos: Poemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "648fd68e",
   "metadata": {
    "id": "648fd68e"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1c3feb23",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1c3feb23",
    "outputId": "edf5a715-46c9-4e51-9539-7fbb5bb57a54"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5133, 3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poems_df = pd.read_csv(\"https://raw.githubusercontent.com/andreamorgar/poesIA/master/data/poems.csv\")\n",
    "poems_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "2745e771",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426
    },
    "id": "2745e771",
    "outputId": "db006061-0343-4169-8188-95ca488c6dd6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-13fce479-74fa-460c-a651-04cf2df20b3b\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "      <th>string</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Leopoldo Lugones</td>\n",
       "      <td>\\n\\nEn el parque confuso\\nQue con lánguidas br...</td>\n",
       "      <td>LA MUERTE DE LA LUNA</td>\n",
       "      <td>\\nLA MUERTE DE LA LUNA\\n\\nLeopoldo Lugones\\n\\n...</td>\n",
       "      <td>1850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marilina Rébora</td>\n",
       "      <td>\\n\\nPorque si tú no velas, vendré como ladrón;...</td>\n",
       "      <td>PORQUE SI TÚ NO VELAS</td>\n",
       "      <td>\\nPORQUE SI TÚ NO VELAS\\n\\nMarilina Rébora\\n\\n...</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Antonio Colinas</td>\n",
       "      <td>\\n\\nPequeña de mis sueños, por tu piel las pal...</td>\n",
       "      <td>POEMA DE LA BELLEZA CAUTIVA QUE PERDÍ</td>\n",
       "      <td>\\nPOEMA DE LA BELLEZA CAUTIVA QUE PERDÍ\\n\\nAnt...</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>José María Hinojosa</td>\n",
       "      <td>\\n\\nLos dedos de la nieve\\nrepiquetearon\\nen e...</td>\n",
       "      <td>SENCILLEZ</td>\n",
       "      <td>\\nSENCILLEZ\\n\\nJosé María Hinojosa\\n\\n\\n\\nLos ...</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rubén Izaguirre Fiallos</td>\n",
       "      <td>Naciste en Armenia,\\npero te fuiste a vivir al...</td>\n",
       "      <td>Breve Carta a Consuelo Suncín</td>\n",
       "      <td>\\nBreve Carta a Consuelo Suncín\\n\\nRubén Izagu...</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Leopoldo María Panero</td>\n",
       "      <td>\\n\\nOscuridad nieve buitres desespero oscurida...</td>\n",
       "      <td>PASADIZO SECRETO</td>\n",
       "      <td>\\nPASADIZO SECRETO\\n\\nLeopoldo María Panero\\n\\...</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gabriela Mistral</td>\n",
       "      <td>\\nSiento mi corazón en la dulzura \\nfundirse c...</td>\n",
       "      <td>Atardecer</td>\n",
       "      <td>\\nAtardecer\\n\\nGabriela Mistral\\n\\n\\nSiento mi...</td>\n",
       "      <td>197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pablo Neruda</td>\n",
       "      <td>Cien sonetos de amor\\n\\nTrajo el amor su cola ...</td>\n",
       "      <td>Cien sonetos de amor</td>\n",
       "      <td>\\nCien sonetos de amor\\n\\nPablo Neruda\\n\\nCien...</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>William Shakespeare</td>\n",
       "      <td>¿Y por qué no es tu guerra más pujante\\ncontra...</td>\n",
       "      <td>Y por qué no es tu guerra más pujante...</td>\n",
       "      <td>\\nY por qué no es tu guerra más pujante...\\n\\n...</td>\n",
       "      <td>566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gabriela Mistral</td>\n",
       "      <td>\\nEl espino prende a una roca \\nsu enloquecida...</td>\n",
       "      <td>El espino</td>\n",
       "      <td>\\nEl espino\\n\\nGabriela Mistral\\n\\n\\nEl espino...</td>\n",
       "      <td>893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Luis de Góngora</td>\n",
       "      <td>\\n\\nSalí, señor don Pedro, esta mañana\\nA ver ...</td>\n",
       "      <td>A DON PEDRO DE CÁRDENAS</td>\n",
       "      <td>\\nA DON PEDRO DE CÁRDENAS\\n\\nLuis de Góngora\\n...</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Rafael Alberti</td>\n",
       "      <td>\\n\\nDecidme de una vez si no fue alegre todo a...</td>\n",
       "      <td>EN EL DÍA DE SU MUERTE A MANO ARMADA</td>\n",
       "      <td>\\nEN EL DÍA DE SU MUERTE A MANO ARMADA\\n\\nRafa...</td>\n",
       "      <td>882</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13fce479-74fa-460c-a651-04cf2df20b3b')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-13fce479-74fa-460c-a651-04cf2df20b3b button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-13fce479-74fa-460c-a651-04cf2df20b3b');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                     author  \\\n",
       "0          Leopoldo Lugones   \n",
       "1           Marilina Rébora   \n",
       "2           Antonio Colinas   \n",
       "3       José María Hinojosa   \n",
       "4   Rubén Izaguirre Fiallos   \n",
       "5     Leopoldo María Panero   \n",
       "6          Gabriela Mistral   \n",
       "7              Pablo Neruda   \n",
       "8       William Shakespeare   \n",
       "9          Gabriela Mistral   \n",
       "10          Luis de Góngora   \n",
       "11           Rafael Alberti   \n",
       "\n",
       "                                              content  \\\n",
       "0   \\n\\nEn el parque confuso\\nQue con lánguidas br...   \n",
       "1   \\n\\nPorque si tú no velas, vendré como ladrón;...   \n",
       "2   \\n\\nPequeña de mis sueños, por tu piel las pal...   \n",
       "3   \\n\\nLos dedos de la nieve\\nrepiquetearon\\nen e...   \n",
       "4   Naciste en Armenia,\\npero te fuiste a vivir al...   \n",
       "5   \\n\\nOscuridad nieve buitres desespero oscurida...   \n",
       "6   \\nSiento mi corazón en la dulzura \\nfundirse c...   \n",
       "7   Cien sonetos de amor\\n\\nTrajo el amor su cola ...   \n",
       "8   ¿Y por qué no es tu guerra más pujante\\ncontra...   \n",
       "9   \\nEl espino prende a una roca \\nsu enloquecida...   \n",
       "10  \\n\\nSalí, señor don Pedro, esta mañana\\nA ver ...   \n",
       "11  \\n\\nDecidme de una vez si no fue alegre todo a...   \n",
       "\n",
       "                                       title  \\\n",
       "0                       LA MUERTE DE LA LUNA   \n",
       "1                      PORQUE SI TÚ NO VELAS   \n",
       "2      POEMA DE LA BELLEZA CAUTIVA QUE PERDÍ   \n",
       "3                                  SENCILLEZ   \n",
       "4              Breve Carta a Consuelo Suncín   \n",
       "5                           PASADIZO SECRETO   \n",
       "6                                  Atardecer   \n",
       "7                       Cien sonetos de amor   \n",
       "8   Y por qué no es tu guerra más pujante...   \n",
       "9                                  El espino   \n",
       "10                   A DON PEDRO DE CÁRDENAS   \n",
       "11      EN EL DÍA DE SU MUERTE A MANO ARMADA   \n",
       "\n",
       "                                               string  length  \n",
       "0   \\nLA MUERTE DE LA LUNA\\n\\nLeopoldo Lugones\\n\\n...    1850  \n",
       "1   \\nPORQUE SI TÚ NO VELAS\\n\\nMarilina Rébora\\n\\n...     732  \n",
       "2   \\nPOEMA DE LA BELLEZA CAUTIVA QUE PERDÍ\\n\\nAnt...     662  \n",
       "3   \\nSENCILLEZ\\n\\nJosé María Hinojosa\\n\\n\\n\\nLos ...     273  \n",
       "4   \\nBreve Carta a Consuelo Suncín\\n\\nRubén Izagu...     416  \n",
       "5   \\nPASADIZO SECRETO\\n\\nLeopoldo María Panero\\n\\...     349  \n",
       "6   \\nAtardecer\\n\\nGabriela Mistral\\n\\n\\nSiento mi...     197  \n",
       "7   \\nCien sonetos de amor\\n\\nPablo Neruda\\n\\nCien...     561  \n",
       "8   \\nY por qué no es tu guerra más pujante...\\n\\n...     566  \n",
       "9   \\nEl espino\\n\\nGabriela Mistral\\n\\n\\nEl espino...     893  \n",
       "10  \\nA DON PEDRO DE CÁRDENAS\\n\\nLuis de Góngora\\n...     584  \n",
       "11  \\nEN EL DÍA DE SU MUERTE A MANO ARMADA\\n\\nRafa...     882  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poems_df.head(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7fa11ef4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7fa11ef4",
    "outputId": "83ac1c24-1970-48c7-d81a-0dbd01589598"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay  3688  poemas después de filtrar por longitud       (considerando una longitud menor de  1000 )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "poems_df = poems_df.dropna()\n",
    "\n",
    "def poem_to_string(poem):\n",
    "    return f'\\n{poem[\"title\"]}\\n{poem[\"author\"]}\\n{poem[\"content\"]}'\n",
    "\n",
    "# Filtramos poemas grandes\n",
    "poems_df['string'] = poems_df.apply(lambda row: f'\\n{row[\"title\"]}\\n\\n{row[\"author\"]}\\n\\n{row[\"content\"]}', axis=1)\n",
    "poems_df['length'] = poems_df.string.map(len)\n",
    "\n",
    "# Consideramos poemas de longitud máxima 1000\n",
    "MAX_POEM_LENGTH=1000\n",
    "poems_filtered = poems_df[poems_df.length<MAX_POEM_LENGTH]\n",
    "\n",
    "print('Hay ', len(poems_filtered), ' poemas después de filtrar por longitud \\\n",
    "      (considerando una longitud menor de ', MAX_POEM_LENGTH, ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5a3e6620",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5a3e6620",
    "outputId": "06d7a1ab-5abc-4b7f-96e4-a9fd3cb70287"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1       \\nPORQUE SI TÚ NO VELAS\\n\\nMarilina Rébora\\n\\n...\n",
       "2       \\nPOEMA DE LA BELLEZA CAUTIVA QUE PERDÍ\\n\\nAnt...\n",
       "3       \\nSENCILLEZ\\n\\nJosé María Hinojosa\\n\\n\\n\\nLos ...\n",
       "4       \\nBreve Carta a Consuelo Suncín\\n\\nRubén Izagu...\n",
       "5       \\nPASADIZO SECRETO\\n\\nLeopoldo María Panero\\n\\...\n",
       "                              ...                        \n",
       "5127    \\nBOSQUE\\n\\nÁngel González\\n\\n\\n\\nCruzas por e...\n",
       "5129    \\nNada es memoria\\n\\nDavid Escobar Galindo\\n\\n...\n",
       "5130    \\nEsto es todo lo que deseo para tí\\n\\namistad...\n",
       "5131    \\nPalpar\\n\\nOctavio Paz\\n\\n\\nMis manos \\nabren...\n",
       "5132    \\nEXORDIO\\n\\nJosé Ángel Valente\\n\\n\\n\\nY ahora...\n",
       "Name: string, Length: 3688, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poems_string = poems_filtered.string\n",
    "poems_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "76c317f7",
   "metadata": {
    "id": "76c317f7"
   },
   "outputs": [],
   "source": [
    "import torchtext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2bac62d8",
   "metadata": {
    "id": "2bac62d8"
   },
   "outputs": [],
   "source": [
    "tokenizer = torchtext.data.utils.get_tokenizer(None, language='es')\n",
    "tokens = [tokenizer(poem) for poem in poems_string]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ebb2324a",
   "metadata": {
    "id": "ebb2324a"
   },
   "outputs": [],
   "source": [
    "chars = tuple(set(poems_string.values[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d4e0bbeb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4e0bbeb",
    "outputId": "cf8aeb03-130f-4c2d-a3ca-d36545f0e629"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('í',\n",
       " 'i',\n",
       " '.',\n",
       " ';',\n",
       " 'A',\n",
       " 'o',\n",
       " ' ',\n",
       " 'j',\n",
       " 'E',\n",
       " 'P',\n",
       " 'y',\n",
       " 'e',\n",
       " '\\n',\n",
       " 'Y',\n",
       " 'M',\n",
       " 'f',\n",
       " 'Q',\n",
       " 'N',\n",
       " 'é',\n",
       " 'U',\n",
       " ',',\n",
       " 'd',\n",
       " 'b',\n",
       " 'u',\n",
       " 'I',\n",
       " 'L',\n",
       " 'á',\n",
       " 'T',\n",
       " 'ó',\n",
       " 'g',\n",
       " 'R',\n",
       " 'Ú',\n",
       " 'r',\n",
       " 'D',\n",
       " 'v',\n",
       " 'l',\n",
       " 'C',\n",
       " 'O',\n",
       " 's',\n",
       " 'ú',\n",
       " 'h',\n",
       " 'S',\n",
       " 'm',\n",
       " 'p',\n",
       " 't',\n",
       " 'V',\n",
       " 'a',\n",
       " 'q',\n",
       " ':',\n",
       " 'n',\n",
       " 'c',\n",
       " '\\x97')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dee35f",
   "metadata": {
    "id": "e8dee35f"
   },
   "source": [
    "enlaces:\n",
    "    https://github.com/LeanManager/NLP-PyTorch/blob/master/Character-Level%20LSTM%20with%20PyTorch.ipynb\n",
    "    https://www.kaggle.com/code/ab971631/beginners-guide-to-text-generation-pytorch/notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1f14f0",
   "metadata": {
    "id": "de1f14f0"
   },
   "source": [
    "## Capas recurrentes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b04ef87",
   "metadata": {
    "id": "5b04ef87"
   },
   "source": [
    "## Modelo de generación de texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ded2233",
   "metadata": {
    "id": "3ded2233"
   },
   "source": [
    "## Modelo preentrenado: Transformers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "add2436b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "add2436b",
    "outputId": "da3f6549-570a-4900-8d65-fda37a4fea7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.21.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.12.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.9.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
      "Wed Sep 14 18:37:56 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   69C    P0    30W /  70W |   1850MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "zXtWsCEVONx9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zXtWsCEVONx9",
    "outputId": "b91f35d6-c00d-437a-9a58-baf4fe40810f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 1.12.1+cu113\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import zipfile\n",
    "import random\n",
    "import time\n",
    "import csv\n",
    "import datetime\n",
    "from itertools import compress\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForPreTraining, \\\n",
    "                         AdamW, get_linear_schedule_with_warmup, \\\n",
    "                         TrainingArguments, BeamScorer, Trainer\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, random_split, DataLoader, \\\n",
    "                             RandomSampler, SequentialSampler\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "kOvPHRYkOWmJ",
   "metadata": {
    "id": "kOvPHRYkOWmJ"
   },
   "outputs": [],
   "source": [
    "DEBUG           = False\n",
    "\n",
    "INPUT_DIR       = 'articles'\n",
    "\n",
    "USE_APEX        = True\n",
    "APEX_OPT_LEVEL  = 'O1'\n",
    "\n",
    "MODEL           = 'gpt2' #{gpt2, gpt2-medium, gpt2-large, gpt2-xl}\n",
    "\n",
    "UNFREEZE_LAST_N = 6 #The last N layers to unfreeze for training\n",
    "\n",
    "SPECIAL_TOKENS  = { \"bos_token\": \"<|BOS|>\",\n",
    "                    \"eos_token\": \"<|EOS|>\",\n",
    "                    \"unk_token\": \"<|UNK|>\",                    \n",
    "                    \"pad_token\": \"<|PAD|>\",\n",
    "                    \"sep_token\": \"<|SEP|>\"}\n",
    "                    \n",
    "MAXLEN          = 768  #{768, 1024, 1280, 1600}\n",
    "\n",
    "TRAIN_SIZE      = 0.8\n",
    "\n",
    "if USE_APEX:\n",
    "    TRAIN_BATCHSIZE = 4\n",
    "    BATCH_UPDATE    = 16\n",
    "else:\n",
    "    TRAIN_BATCHSIZE = 2\n",
    "    BATCH_UPDATE    = 32\n",
    "\n",
    "EPOCHS          = 4\n",
    "LR              = 5e-4\n",
    "EPS             = 1e-8\n",
    "WARMUP_STEPS    = 1e2\n",
    "\n",
    "SEED            = 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "HQzYhvrtOZ57",
   "metadata": {
    "id": "HQzYhvrtOZ57"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "AdpbReT-ObQq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "AdpbReT-ObQq",
    "outputId": "90d09aa5-7515-47a1-8b1e-043a990f4131"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-05cfb379-9240-4515-aba7-92dc9c800884\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>title</th>\n",
       "      <th>string</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marilina Rébora</td>\n",
       "      <td>\\n\\nPorque si tú no velas, vendré como ladrón;...</td>\n",
       "      <td>PORQUE SI TÚ NO VELAS</td>\n",
       "      <td>\\nPORQUE SI TÚ NO VELAS\\n\\nMarilina Rébora\\n\\n...</td>\n",
       "      <td>732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Antonio Colinas</td>\n",
       "      <td>\\n\\nPequeña de mis sueños, por tu piel las pal...</td>\n",
       "      <td>POEMA DE LA BELLEZA CAUTIVA QUE PERDÍ</td>\n",
       "      <td>\\nPOEMA DE LA BELLEZA CAUTIVA QUE PERDÍ\\n\\nAnt...</td>\n",
       "      <td>662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>José María Hinojosa</td>\n",
       "      <td>\\n\\nLos dedos de la nieve\\nrepiquetearon\\nen e...</td>\n",
       "      <td>SENCILLEZ</td>\n",
       "      <td>\\nSENCILLEZ\\n\\nJosé María Hinojosa\\n\\n\\n\\nLos ...</td>\n",
       "      <td>273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rubén Izaguirre Fiallos</td>\n",
       "      <td>Naciste en Armenia,\\npero te fuiste a vivir al...</td>\n",
       "      <td>Breve Carta a Consuelo Suncín</td>\n",
       "      <td>\\nBreve Carta a Consuelo Suncín\\n\\nRubén Izagu...</td>\n",
       "      <td>416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Leopoldo María Panero</td>\n",
       "      <td>\\n\\nOscuridad nieve buitres desespero oscurida...</td>\n",
       "      <td>PASADIZO SECRETO</td>\n",
       "      <td>\\nPASADIZO SECRETO\\n\\nLeopoldo María Panero\\n\\...</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05cfb379-9240-4515-aba7-92dc9c800884')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-05cfb379-9240-4515-aba7-92dc9c800884 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-05cfb379-9240-4515-aba7-92dc9c800884');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                    author                                            content  \\\n",
       "1          Marilina Rébora  \\n\\nPorque si tú no velas, vendré como ladrón;...   \n",
       "2          Antonio Colinas  \\n\\nPequeña de mis sueños, por tu piel las pal...   \n",
       "3      José María Hinojosa  \\n\\nLos dedos de la nieve\\nrepiquetearon\\nen e...   \n",
       "4  Rubén Izaguirre Fiallos  Naciste en Armenia,\\npero te fuiste a vivir al...   \n",
       "5    Leopoldo María Panero  \\n\\nOscuridad nieve buitres desespero oscurida...   \n",
       "\n",
       "                                   title  \\\n",
       "1                  PORQUE SI TÚ NO VELAS   \n",
       "2  POEMA DE LA BELLEZA CAUTIVA QUE PERDÍ   \n",
       "3                              SENCILLEZ   \n",
       "4          Breve Carta a Consuelo Suncín   \n",
       "5                       PASADIZO SECRETO   \n",
       "\n",
       "                                              string  length  \n",
       "1  \\nPORQUE SI TÚ NO VELAS\\n\\nMarilina Rébora\\n\\n...     732  \n",
       "2  \\nPOEMA DE LA BELLEZA CAUTIVA QUE PERDÍ\\n\\nAnt...     662  \n",
       "3  \\nSENCILLEZ\\n\\nJosé María Hinojosa\\n\\n\\n\\nLos ...     273  \n",
       "4  \\nBreve Carta a Consuelo Suncín\\n\\nRubén Izagu...     416  \n",
       "5  \\nPASADIZO SECRETO\\n\\nLeopoldo María Panero\\n\\...     349  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poems_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3byWg7d0OoaP",
   "metadata": {
    "id": "3byWg7d0OoaP"
   },
   "outputs": [],
   "source": [
    "# create data object\n",
    "df_dict = poems_filtered.to_dict('records')\n",
    "data = {}\n",
    "cont = 0\n",
    "for item in df_dict:\n",
    "  data[cont] = [item['title'],item['content'],item['author']]\n",
    "  cont +=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "T1AR7j3gPMwe",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T1AR7j3gPMwe",
    "outputId": "cdeba065-5767-4a4d-81bb-a84bf509f798"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PORQUE SI TÚ NO VELAS',\n",
       " '\\n\\nPorque si tú no velas, vendré como ladrón;\\nhe de llegar a ti sin que sepas la hora.\\nEstate alerta, pues; vigila cada acción,\\ny lo que has recibido y escuchado, memora.\\n\\nAunque nombre de vivo posees, estás muerto;\\nperfectas, ante Dios, no he encontrado tus obras.\\nConsolídalas pronto o han de morir por cierto,\\nsi es que no te arrepientes y de otro modo obras.\\n\\nYo soy El de las siete estrellas a su diestra;\\nEl que en los siete Espíritus de Dios, único, arde.\\nVestirá el que venciere de blancas vestiduras.\\nDel libro de la vida, su nombre \\x97santa muestra\\x97\\njamás he de borrar, lo diré en las alturas.\\nVendré como ladrón: igual, temprano o tarde.\\nVendré como ladrón, de improviso o a oscuras.',\n",
       " 'Marilina Rébora']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f8TtOEfXPOl8",
   "metadata": {
    "id": "f8TtOEfXPOl8"
   },
   "outputs": [],
   "source": [
    "class myDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, tokenizer, randomize=True):\n",
    "\n",
    "        title, content, author = [], [], []\n",
    "        for k, v in data.items():\n",
    "            title.append(v[2])\n",
    "            content.append(v[1])\n",
    "            author.append(v[0])\n",
    "\n",
    "        self.randomize = randomize\n",
    "        self.tokenizer = tokenizer\n",
    "        self.title = title\n",
    "        self.content = content\n",
    "        self.author = author\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.content)\n",
    "\n",
    "    # ---------------------------------------------#\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        # keywords = self.keywords[i].copy()\n",
    "        # kw = self.join_keywords(keywords, self.randomize)\n",
    "\n",
    "        input = SPECIAL_TOKENS['bos_token'] + self.title[i] + \\\n",
    "                SPECIAL_TOKENS['sep_token'] + self.author[i] + SPECIAL_TOKENS['sep_token'] + \\\n",
    "                self.content[i] + SPECIAL_TOKENS['eos_token']\n",
    "\n",
    "        encodings_dict = tokenizer(input,\n",
    "                                   truncation=True,\n",
    "                                   max_length=MAXLEN,\n",
    "                                   padding=\"max_length\")\n",
    "\n",
    "        input_ids = encodings_dict['input_ids']\n",
    "        attention_mask = encodings_dict['attention_mask']\n",
    "\n",
    "        return {'label': torch.tensor(input_ids),\n",
    "                'input_ids': torch.tensor(input_ids),\n",
    "                'attention_mask': torch.tensor(attention_mask)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "atHmqrUxPYKm",
   "metadata": {
    "id": "atHmqrUxPYKm"
   },
   "outputs": [],
   "source": [
    "def split_data(data, S=TRAIN_SIZE):\n",
    "    # Shuffle ids\n",
    "    ids = list(data.keys())\n",
    "    random.shuffle(ids)\n",
    "\n",
    "    # Split into training and validation sets\n",
    "    train_size = int(S * len(data))\n",
    "\n",
    "    train_ids = ids[:train_size]\n",
    "    val_ids = ids[train_size:]\n",
    "\n",
    "    train_data = dict()\n",
    "    for id in train_ids:\n",
    "        train_data[id] = data[id]\n",
    "\n",
    "    val_data = dict()\n",
    "    for id in val_ids:\n",
    "        val_data[id] = data[id]\n",
    "\n",
    "    return train_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "FdBuvLPBPwgF",
   "metadata": {
    "id": "FdBuvLPBPwgF"
   },
   "outputs": [],
   "source": [
    "def get_tokenier(special_tokens=None):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL) #GPT2Tokenizer\n",
    "\n",
    "    if special_tokens:\n",
    "        tokenizer.add_special_tokens(special_tokens)\n",
    "        print(\"Special tokens added\")\n",
    "    return tokenizer\n",
    "\n",
    "def get_model(tokenizer, special_tokens=None, load_model_path=None):\n",
    "\n",
    "    #GPT2LMHeadModel\n",
    "    if special_tokens:\n",
    "        config = AutoConfig.from_pretrained(MODEL,\n",
    "                                            bos_token_id=tokenizer.bos_token_id,\n",
    "                                            eos_token_id=tokenizer.eos_token_id,\n",
    "                                            sep_token_id=tokenizer.sep_token_id,\n",
    "                                            pad_token_id=tokenizer.pad_token_id,\n",
    "                                            output_hidden_states=False)\n",
    "    else:\n",
    "        config = AutoConfig.from_pretrained(MODEL,\n",
    "                                            pad_token_id=tokenizer.eos_token_id,\n",
    "                                            output_hidden_states=False)\n",
    "\n",
    "    #----------------------------------------------------------------#\n",
    "    model = AutoModelForPreTraining.from_pretrained(MODEL, config=config)\n",
    "\n",
    "    if special_tokens:\n",
    "        #Special tokens added, model needs to be resized accordingly\n",
    "        model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "    if load_model_path:\n",
    "        model.load_state_dict(torch.load(load_model_path))\n",
    "\n",
    "    model.cuda()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "N2RAnM4ZP4XS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N2RAnM4ZP4XS",
    "outputId": "7b0d3e75-b651-40cf-c728-a498f47772b7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/gpt2/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/684fe667923972fb57f6b4dcb61a3c92763ad89882f3da5da9866baf14f2d60f.c7ed1f96aac49e745788faa77ba0a26a392643a50bb388b9c04ff469e555241f\n",
      "loading file https://huggingface.co/gpt2/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/c0c761a63004025aeadd530c4c27b860ec4ecbe8a00531233de21d865a402598.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "loading file https://huggingface.co/gpt2/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/16a2f78023c8dc511294f0c97b5e10fde3ef9889ad6d11ffaa2a00714e73926e.cf2d0ecb83b6df91b3dbb53f1d1e4c311578bfd3aa0e04934215a49bf9898df0\n",
      "loading file https://huggingface.co/gpt2/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/gpt2/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/gpt2/resolve/main/tokenizer_config.json from cache at None\n",
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50256,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n",
      "Assigning <|BOS|> to the bos_token key of the tokenizer\n",
      "Assigning <|EOS|> to the eos_token key of the tokenizer\n",
      "Assigning <|UNK|> to the unk_token key of the tokenizer\n",
      "Assigning <|PAD|> to the pad_token key of the tokenizer\n",
      "Assigning <|SEP|> to the sep_token key of the tokenizer\n",
      "loading configuration file https://huggingface.co/gpt2/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/fc674cd6907b4c9e933cb42d67662436b89fa9540a1f40d7c919d0109289ad01.7d2e0efa5ca20cef4fb199382111e9d3ad96fd77b849e1d4bed13a66e1336f51\n",
      "Model config GPT2Config {\n",
      "  \"_name_or_path\": \"gpt2\",\n",
      "  \"activation_function\": \"gelu_new\",\n",
      "  \"architectures\": [\n",
      "    \"GPT2LMHeadModel\"\n",
      "  ],\n",
      "  \"attn_pdrop\": 0.1,\n",
      "  \"bos_token_id\": 50257,\n",
      "  \"embd_pdrop\": 0.1,\n",
      "  \"eos_token_id\": 50258,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"layer_norm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"gpt2\",\n",
      "  \"n_ctx\": 1024,\n",
      "  \"n_embd\": 768,\n",
      "  \"n_head\": 12,\n",
      "  \"n_inner\": null,\n",
      "  \"n_layer\": 12,\n",
      "  \"n_positions\": 1024,\n",
      "  \"pad_token_id\": 50260,\n",
      "  \"reorder_and_upcast_attn\": false,\n",
      "  \"resid_pdrop\": 0.1,\n",
      "  \"scale_attn_by_inverse_layer_idx\": false,\n",
      "  \"scale_attn_weights\": true,\n",
      "  \"sep_token_id\": 50261,\n",
      "  \"summary_activation\": null,\n",
      "  \"summary_first_dropout\": 0.1,\n",
      "  \"summary_proj_to_labels\": true,\n",
      "  \"summary_type\": \"cls_index\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"task_specific_params\": {\n",
      "    \"text-generation\": {\n",
      "      \"do_sample\": true,\n",
      "      \"max_length\": 50\n",
      "    }\n",
      "  },\n",
      "  \"transformers_version\": \"4.21.3\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50257\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special tokens added\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file https://huggingface.co/gpt2/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/752929ace039baa8ef70fe21cdf9ab9445773d20e733cf693d667982e210837e.323c769945a351daa25546176f8208b3004b6f563438a7603e7932bae9025925\n",
      "All model checkpoint weights were used when initializing GPT2LMHeadModel.\n",
      "\n",
      "All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = get_tokenier(special_tokens=SPECIAL_TOKENS)\n",
    "\n",
    "model = get_model(tokenizer, special_tokens=SPECIAL_TOKENS,\n",
    "                #   load_model_path='pytorch_model.bin'\n",
    "                 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "VNirC6qVQJaz",
   "metadata": {
    "id": "VNirC6qVQJaz"
   },
   "outputs": [],
   "source": [
    "# - Freeze selective layers:\n",
    "# - Freeze all layers except last n:\n",
    "for parameter in model.parameters():\n",
    "    parameter.requires_grad = False\n",
    "\n",
    "for i, m in enumerate(model.transformer.h):\n",
    "    #Only un-freeze the last n transformer blocks\n",
    "    if i+1 > 12 - UNFREEZE_LAST_N:\n",
    "        for parameter in m.parameters():\n",
    "            parameter.requires_grad = True\n",
    "\n",
    "for parameter in model.transformer.ln_f.parameters():\n",
    "    parameter.requires_grad = True\n",
    "\n",
    "for parameter in model.lm_head.parameters():\n",
    "    parameter.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "OcosBnVGQMqG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "OcosBnVGQMqG",
    "outputId": "7a3170d3-f873-4fa5-b51d-1f8d60adbb98"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'There are 2,950 samples for training, and 738 samples for validation testing'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data, val_data = split_data(data)\n",
    "\n",
    "train_dataset = myDataset(train_data, tokenizer)\n",
    "val_dataset = myDataset(val_data, tokenizer, randomize=False)\n",
    "\n",
    "f'There are {len(train_dataset) :,} samples for training, and {len(val_dataset) :,} samples for validation testing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "z7xs7kDpQUe8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 495
    },
    "id": "z7xs7kDpQUe8",
    "outputId": "c688953f-81a4-436b-9aed-4f365c2a6a04"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using `logging_steps` to initialize `eval_steps` to 500\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using cuda_amp half precision backend\n",
      "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 2950\n",
      "  Num Epochs = 4\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 16\n",
      "  Total optimization steps = 184\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='184' max='184' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [184/184 20:22, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to /content/\n",
      "Configuration saved in /content/config.json\n",
      "Model weights saved in /content/pytorch_model.bin\n",
      "tokenizer config file saved in /content/tokenizer_config.json\n",
      "Special tokens file saved in /content/special_tokens_map.json\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/content/\",\n",
    "    num_train_epochs=EPOCHS,\n",
    "    per_device_train_batch_size=TRAIN_BATCHSIZE,\n",
    "    per_device_eval_batch_size=TRAIN_BATCHSIZE,\n",
    "    gradient_accumulation_steps=BATCH_UPDATE,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    fp16=True,\n",
    "    fp16_opt_level=APEX_OPT_LEVEL,\n",
    "    warmup_steps=WARMUP_STEPS,    \n",
    "    learning_rate=LR,\n",
    "    adam_epsilon=EPS,\n",
    "    weight_decay=0.01,        \n",
    "    save_total_limit=1,\n",
    "    load_best_model_at_end=True\n",
    "    )\n",
    "\n",
    "#---------------------------------------------------#\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,    \n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "#---------------------------------------------------#\n",
    "trainer.train()\n",
    "trainer.save_model()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "Ql7x3xuadD7S",
   "metadata": {
    "id": "Ql7x3xuadD7S"
   },
   "outputs": [],
   "source": [
    "title = \"Días sin ti\"\n",
    "author = 'Rafael Alberti'\n",
    "\n",
    "prompt = SPECIAL_TOKENS['bos_token'] + title + \\\n",
    "         SPECIAL_TOKENS['sep_token'] + author + SPECIAL_TOKENS['sep_token']\n",
    "         \n",
    "generated = torch.tensor(tokenizer.encode(prompt)).unsqueeze(0)\n",
    "device = torch.device(\"cuda\")\n",
    "generated = generated.to(device)\n",
    "\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "DtSzkUFAdUSC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DtSzkUFAdUSC",
    "outputId": "74bc1879-d1f0-4b26-c662-0b7346722552"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: \n",
      "¿Por qué me visto en tus ojos?  Amarillo, que a la noche es un día de sus más luces; y sólo parece el mundial se lejan. (El alma amargo.)\n",
      "Luego porque todavies no lo despoja: ni mi corazón con las manchillas del agua comienza bajo su espalda! No hay caminaron los huesales escribirme... ¡Quieran te llamaste está triste ya frente!, tu mirada verde tan rostro serpientes hastútiles hablenado!?  Dejarse yo nunca veces muertinas entre sueñores frontera velando nosotros moradas cuidados sonrachios...?\n",
      "\n",
      "\n",
      "2: \n",
      "No tienen el agua que algo, nadie una oscura. No es tan cómo en las palabras: iba no se queda por los labios y despojos; si estoy la luz de amor me hace mi boca conmigo del corazón! ¡Qué siempre vuelo a darme!, tu carneza entre rutina mirada» (Sobrevía)\n",
      "\n",
      "Amor yo nosotros comunidades cuando te llora sucedido...\n",
      "Que puede lo escuchamores más leyes perdida encontrarándomeñales-seguir ya sonrisamentes-, saberán mis dedicados verdes niño). Ya hastan todo hablaban fue ahogado aprendidas?\n",
      "\n",
      "\n",
      "3: \n",
      "¡Ya, qué hacer! ¿Porque tú siento a los pájaros?  La esperanza se vuestra la noche. El sol de un íntimo en el agua día; no soy al ciel otra que mi lado y más paloma su rostro?... No te acaba las puertes del amante: por lo mismeza sonrece con tu corazón bajo llora rico niñales comenzaron ha sidóndomeña todo me perdido frenteceránica para sus hojas...?\n",
      "\n",
      "\n",
      "4: \n",
      "Tú, y yo no se siempre me hacer de un árbol.\n",
      "¿Qué vuelve? La luz del mundo que la noche: y tienen!  El aire al olvido en las pájaros rosales; con el silencio día cómo trabajado espejo por los desvelados... No te amor levanta estás bajo mi pecho tu corazón su arrozano (la muerte). Y si lo sabes cuando todo sobre mis sonrisadas fiel dos niñezarán verdad comenzaron -?Y quieran entre solamente tan rama fueron causa haberlo abrancida... quedamientra este ser templidad», andada para sus frutidades aparecionel aguardables hastoycementeadares asombrantes muertres inmensiosante encontrarme-nosotros contigo morirsemosias?: «No hay ahora nos somblores ya lluvialisendo aquella blanca puraciene fuego!?\n",
      "\n",
      "\n",
      "5: \n",
      "La puerta de la piel llorarme, aunque no me sé en el cuerpo.\n",
      "Llama y llamada al fin del agua; como un día llegado se vuelta... No hay que ya lo pasaba todos nadierenes!\n",
      "\n",
      "\n",
      "6: \n",
      "Siempre de luz y espejo, la noche que te habrá el agua.  Ya no me miran con tu viento; al fin se hace mi canto en más sombra a las rosales!\n",
      "\n",
      "\n",
      "7: \n",
      "Y si el día que te hemos en la tierra de las huesos, iba más con sus rosales. ¡Qué me llamarme es una piedad! ¿Cómo sabe tu boca y alma? No seguro otra noche; como los dos tres ciegantes del sol deseletezado? Y porque no hay lejana: «No quieren está vida»... Sobre mi luz hastan su amoroso alegrable lo infanciaño ya nunca faltura!?  El corazón son escribirse rompando todo entonces yo niña ella recuerda verdadamentes heridades serán para nuestros frutilados ataques...? Yo soy aquelante mis pies quién tristecementen abrazadas hablando encuentro vivo contrajoza! Aungo perdido era él agua nosotriarte azulada juntarla inmortalidad sobre este pozo-pico dañuelto - íntima mismina fue buscaba negranas horanos tan cortinas\n",
      "\n",
      "comiencia veintento igual cuartano aparecerlo de flores allende irissoy contigo va decinero\n",
      "de salud ardientementez pasaban caerizarse creciosa mancha palabrasco madrugares galeros través vengançidas adormantamio comprendimera negociendo?)\n",
      "\n",
      "\n",
      "8: \n",
      "La vida de una piedra, y la muerte: «¡Oh sé que no lo me amar!»  No es el agua te quedarse en las manos a los dos; ¿quisiera al mundo tu corazón?  Aunque mi boca nueva por su cabeza día.  En este estrellada se hacerlo tiempo yo conmigo...\n",
      "\n",
      "\n",
      "9: \n",
      "¡Porque en mi alma, cálido y no me siempre! ¿Amor más dulce años que pueden?  No hay hacerme el olvidado.  En la tierra de tu corazón: eso una noche se vida; por los últimatos ni lo misme rosa...  Y si te qué rastro para todo estoy su llanto con sus tristes entre las aguardines - ahora aquella blanca eternidad del mar deshace tus manchados comeranadas! La casaba hablarleza escribirse abren sonrisamentada amigo bajo llegó asombrador-de verso frentecía, ya hastaque levantadura sobre nuestros pasando muertres perdidarte...?\n",
      "\n",
      "\n",
      "10: \n",
      "El corazón de los árboles, llorar el alma y la vida. Y yo en todo mi otra su rostro con una lluvia; ¿qué es mía? Aunque no estás por quererme hace tu cabeza añeja?, me acuerda como si amigo...Por que lo pueden tambie tan llevaba! Yo te desnuda: \"Es nada fuera para siempre se hablando\" (No hay sobre las palabras). No sabes muertos hastá ni nosotros donde entonces del rincado blanca.\" Ya nunca sonrana ya soy cuando caerse encontrarla era sus trinos lejano-tendirte inmóvilanamentezura.)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Top-p (nucleus) text generation (10 samples):\n",
    "sample_outputs = model.generate(generated, \n",
    "                                do_sample=True,   \n",
    "                                min_length=50, \n",
    "                                max_length=MAXLEN,\n",
    "                                top_k=30,                                 \n",
    "                                top_p=0.7,        \n",
    "                                temperature=0.9,\n",
    "                                repetition_penalty=2.0,\n",
    "                                num_return_sequences=10\n",
    "                                )\n",
    "\n",
    "for i, sample_output in enumerate(sample_outputs):\n",
    "    text = tokenizer.decode(sample_output, skip_special_tokens=True)\n",
    "    a = len(title) + len(author)    \n",
    "    print(\"{}: {}\\n\\n\".format(i+1,  text[a:]))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
