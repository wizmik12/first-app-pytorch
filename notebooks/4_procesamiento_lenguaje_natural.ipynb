{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e16a9ce4",
   "metadata": {},
   "source": [
    "# 4. Procesamiento de Lenguaje Natural\n",
    "\n",
    "Otro de los campos de aplicación para los que más se utiliza PyTorch es para el Procesamiento de Lenguaje Natural (NLP), donde se ha convertido en una de las librerías estrella para el diseño e implementación de modelos de lenguaje sofisticados, por ejemplo, para traducción automática o generación de texto. En este taller se muestran aspectos clave para comenzar tu recorrido pythonero en el mundo del NLP. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9030854",
   "metadata": {},
   "source": [
    "## Antes de comenzar...\n",
    "\n",
    "De nuevo cargamos la librería de Pytorch, y en este caso además *torchtext*, que contiene las funcionalidades necesarias para trabajar con texto con Pytorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1c2d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "from torchinfo import summary\n",
    "from torchnlp import *\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ba5d7f",
   "metadata": {},
   "source": [
    "## Carga del Dataset AG_NEWS\n",
    "\n",
    "En este experimento utilizaremos el dataset AG_NEWS, que nos permitirá llevar a cabo tareas de clasificación de documentos en las categorías contempladas por el dataset: world, sports, business, sci/tech. Este dataset es muy sencillo de cargar y utilizar, puesto que viene por defecto en la librería *torchtext*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4cbc380",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = torchtext.datasets.AG_NEWS(root='../data')\n",
    "classes = ['World', 'Sports', 'Business', 'Sci/Tech']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e3c7ed",
   "metadata": {},
   "source": [
    "## Tokenización del texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6a56fa",
   "metadata": {},
   "source": [
    "Cuando queremos abordar tareas de procesamiento de lenguaje natural, tenemos que tomar la decisión de qué mínima unidad de representación utilizar.  Podemos trabajar, por ejemplo, a nivel de caracter, a nivel de palabra, o a nivel de frase. Esta decisión suele venir tomada por diversas razones, como puede ser las características propias del dataset, el método en concreto que queramos aplicar, y por supuesto, la tarea final en cuestión. \n",
    "\n",
    "En nuestro caso, hemos decidido trabajar a nivel de palabra, una de las formas más utilizadas, y que además nos permite abordar de forma sencilla la clasificación a nivel de documento. Si lo razonamos, una idea intuitiva para realizar dicha clasificación sería intentar identificar patrones/expresiones/relaciones claras a nivel de frase para determinar a qué categoría pertenece un texto. \n",
    "\n",
    "En nuestro caso hemos usado el tokenizador *basic_english* porque nos permite un tratamiento sencillo del texto en inglés a nivel de palabra, pero podríamos importar tokenizadores propios, de otras librerías como *Gensim* o *Spacy*, o incluso implementarlos nosotros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a534d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ab6f00",
   "metadata": {},
   "source": [
    "Al usar la clase *Counter*, podemos detectar todos los tokens que se encuentran en nuestro dataset (lo que a partir de ahora será nuestro vocabulario). Cada uno de estos tokens tiene asociada una cifra única. \n",
    "\n",
    "Finalmente almacenarlos en un objeto de la clase *colab*, encargada de almacenar y manejar vocabularios de un corpus. Con su método *stoi()* podemos recuperar la codificación de las palabras del vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5888b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter()\n",
    "for (label, line) in train_dataset:\n",
    "    counter.update(tokenizer(line))\n",
    "vocab_ = torchtext.vocab.vocab(counter)\n",
    "\n",
    "vocab_size = len(vocab_)\n",
    "\n",
    "stoi = vocab_.get_stoi()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7165aad7",
   "metadata": {},
   "source": [
    "Veamos el resultado de tokenizar noticias del dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40abd66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "first token list:\n",
      "['wall', 'st', '.', 'bears', 'claw', 'back', 'into', 'the', 'black', '(', 'reuters', ')', 'reuters', '-', 'short-sellers', ',', 'wall', 'street', \"'\", 's', 'dwindling\\\\band', 'of', 'ultra-cynics', ',', 'are', 'seeing', 'green', 'again', '.']\n",
      "\n",
      "second token list:\n",
      "['carlyle', 'looks', 'toward', 'commercial', 'aerospace', '(', 'reuters', ')', 'reuters', '-', 'private', 'investment', 'firm', 'carlyle', 'group', ',', '\\\\which', 'has', 'a', 'reputation', 'for', 'making', 'well-timed', 'and', 'occasionally\\\\controversial', 'plays', 'in', 'the', 'defense', 'industry', ',', 'has', 'quietly', 'placed\\\\its', 'bets', 'on', 'another', 'part', 'of', 'the', 'market', '.']\n"
     ]
    }
   ],
   "source": [
    "train_dataset = list(train_dataset)\n",
    "test_dataset = list(test_dataset)\n",
    "\n",
    "\n",
    "first_sentence = train_dataset[0][1]\n",
    "second_sentence = train_dataset[1][1]\n",
    "\n",
    "f_tokens = tokenizer(first_sentence)\n",
    "s_tokens = tokenizer(second_sentence)\n",
    "\n",
    "print(f'\\nfirst token list:\\n{f_tokens}')\n",
    "print(f'\\nsecond token list:\\n{s_tokens}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8388ba8",
   "metadata": {},
   "source": [
    "## Codificación del texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c1fedf",
   "metadata": {},
   "source": [
    "Para poder trabajar con entradas textuales en una red neuronal necesitamos una transformación previa que nos permita obtener una codificación numérica a partir del texto. A esta codificación numérica la llamamos **embedding** y se realiza sobre el conjunto de tokens que forma la sentencia.  \n",
    "\n",
    "Podemos obtener una representación numérica del texto asociándole una cifra numérica a cada token de la secuencia. De esta forma, también podemos hacer la transformación inversa y obtener un texto a partir de los tokens generados y manejados por la red neuronal internamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d3d991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x):\n",
    "    # print([vocab[s] for s in tokenizer(x)])\n",
    "    return [stoi[s] for s in tokenizer(x)]\n",
    "\n",
    "vec = encode(first_sentence) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632dc73b",
   "metadata": {},
   "source": [
    "### Ejemplo\n",
    "\n",
    "A continuación vemos un ejemplo del resultado obtenido tras emplear el tokenizador. Partimos de la siguiente sentencia: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a939b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again. Sentencia\n"
     ]
    }
   ],
   "source": [
    "first_sentence = train_dataset[0][1]\n",
    "print(first_sentence, \"Sentencia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd76ee5f",
   "metadata": {},
   "source": [
    "Los tokens que se obtienen de dicha sentencia están mostrados a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17d2008e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wall', 'st', '.', 'bears', 'claw', 'back', 'into', 'the', 'black', '(', 'reuters', ')', 'reuters', '-', 'short-sellers', ',', 'wall', 'street', \"'\", 's', 'dwindling\\\\band', 'of', 'ultra-cynics', ',', 'are', 'seeing', 'green', 'again', '.'] Tokens asociados a la sentencia\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer(first_sentence), \"Tokens asociados a la sentencia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83bd53f",
   "metadata": {},
   "source": [
    "Y la codificación de la sentencia finalmente es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5717518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 10, 12, 13, 14, 0, 15, 16, 17, 18, 19, 20, 14, 21, 22, 23, 24, 2] <- Embedding\n"
     ]
    }
   ],
   "source": [
    "vec = encode(first_sentence)\n",
    "print(vec, \"<- Embedding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23509396",
   "metadata": {},
   "source": [
    "## Modelo de bolsa de palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0503eb",
   "metadata": {},
   "source": [
    "Para mostrar un ejemplo de uso de Pytorch para un modelo de lenguaje vamos a construir uno de los modelos más sencillos, conocido como **bolsa de palabras**. Tal y como la propia definición indica, estos modelos consideran las secuencias de entrada como conjuntos de palabras. En función de las palabras que forman una noticia, esta se clasifica en una o en otra clase. Es importante tener en cuenta que se trata de conjuntos de tokens que no consideran el orden original de dichos tokens en el texto. \n",
    "\n",
    "En nuestro caso, vamos a utilizar el conjunto de noticias que cargamos al principio del notebook para realizar un problema de **clasificación de documentos** y clasificar las noticias en función de su temática.\n",
    "\n",
    "Podemos definir una bolsa de palabras como un vector (o tensor) de ceros donde los tokens que aparecen en el texto toman valor distinto de 0 usando para ello la posición del vector). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96a377ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentencia:\n",
      "Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\n",
      "\\Bolsa de palabras asociada:\n",
      "tensor([2., 1., 2.,  ..., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "def to_bow(text,bow_vocab_size=vocab_size):\n",
    "    res = torch.zeros(bow_vocab_size,dtype=torch.float32)\n",
    "    for i in encode(text):\n",
    "        if i<bow_vocab_size:\n",
    "            res[i] += 1\n",
    "    return res\n",
    "\n",
    "print(f\"Sentencia:\\n{train_dataset[0][1]}\")\n",
    "print(f\"\\Bolsa de palabras asociada:\\n{to_bow(train_dataset[0][1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f66e14",
   "metadata": {},
   "source": [
    "> **Ejercicio 1**: ¿Qué significa el valor 2 en la primera posición del vector?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f1b424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2936d3ed",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede65aab",
   "metadata": {},
   "source": [
    "Ahora encapsulamos nuestros conjuntos de train y test, ya codificados anteriormente, en objetos DataLoader para proceder a entrenar el modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b7d19c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import numpy as np \n",
    "\n",
    "def bowify(b):\n",
    "    return (\n",
    "            torch.LongTensor([t[0]-1 for t in b]),\n",
    "            torch.stack([to_bow(t[1]) for t in b])\n",
    "    )\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, collate_fn=bowify, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, collate_fn=bowify, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bdd523",
   "metadata": {},
   "source": [
    "Es un modelo muy sencillo, por lo que nuestra red se basa en una capa Sequential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bd4c027",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(torch.nn.Linear(vocab_size,4),torch.nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a4de94",
   "metadata": {},
   "source": [
    "Y una vez tenemos implementada la red, entrenamos el modelo de la forma que hemos venido haciendo a lo largo del taller. ¡Ya somos expertos!. En este caso, hemos implementado el entrenamiento para una sola época, puesto que los modelos de lenguaje son costosos computacionalmente, y este modelo además es sencillo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7af25c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(net,dataloader,lr=0.01,optimizer=None,loss_fn = torch.nn.NLLLoss(),epoch_size=None, report_freq=200):\n",
    "    optimizer = optimizer or torch.optim.Adam(net.parameters(),lr=lr)\n",
    "    net.train()\n",
    "    total_loss,acc,count,i = 0,0,0,0\n",
    "    for labels,features in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        out = net(features)\n",
    "        loss = loss_fn(out,labels) #cross_entropy(out,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss+=loss\n",
    "        _,predicted = torch.max(out,1)\n",
    "        acc+=(predicted==labels).sum()\n",
    "        count+=len(labels)\n",
    "        i+=1\n",
    "        if i%report_freq==0:\n",
    "            print(f\"{count}: acc={acc.item()/count}\")\n",
    "        if epoch_size and count>epoch_size:\n",
    "            break\n",
    "    return total_loss.item()/count, acc.item()/count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6748322",
   "metadata": {},
   "source": [
    "### ¡A entrenar! 🏋🏼‍♀️"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1937c806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200: acc=0.8071875\n",
      "6400: acc=0.83453125\n",
      "9600: acc=0.85125\n",
      "12800: acc=0.8615625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.02603057300104007, 0.8654717484008528)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_epoch(net,train_loader,epoch_size=15000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87341e78",
   "metadata": {},
   "source": [
    "# Pytorch Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f80dfcc",
   "metadata": {},
   "source": [
    "No podemos hablar de PyTorch y procesamiento de lenguaje natural sin mencionar la librería **transformers** de Hugging Face🤗.\n",
    "\n",
    "A pesar de las grandes ventajas que da Pytorch a la hora de implementar modelos para NLP, en proyectos grandes y con redes neuronales complejas lo que se suele hacer es combinar su uso con el de la librería **transformers**. Esta librería contiene implementaciones de PyTorch de modelos de lenguaje asentados y muy utilizados actualmente, así como modelos pre-entrenados que podemos cargar directamente para su uso, ¡y mucho más! \n",
    "\n",
    "Aunque puedes usar Transformers por sí solo, una aplicación normalmente requiere su combinación con funcionalidades de la librería PyTorch, por ejemplo, para el uso de datasets y preprocesamiento de los datos. ¡Podrías aplicar todo lo aprendido durante este taller! \n",
    "\n",
    "Esta librería opera como una capa intermedia entre nuestra implementación y la librería PyTorch, permitiendo entrenar y utilizar modelos sofisticados de procesamiento de lenguaje natural en cuestión de muy pocas líneas de código. Prueba de ello es su funcionalidad *pipeline* que se encarga de cargar automáticamente todo lo necesario para ejecutar un modelo, para que únicamente te preocupes de tu tarea final.\n",
    "\n",
    "### ¡Veamos un ejemplo!\n",
    "Podemos usar *pipeline* con un modelo de clasificación de sentimientos. Con tres líneas hemos podido saber si un texto contiene connotaciones positivas o negativas. 😳🤯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66bfd411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9984990358352661}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I am super excited because I've been waiting for a Python Conference in Granada my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "313dddfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9980828762054443}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"I've been waiting for a Python Conference in Granada my whole life. Miguel and Andrea are really disgusting people.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03334d76",
   "metadata": {},
   "source": [
    "> **Ejercicio 2**: elige otro problema de procesamiento de lenguaje natural, e intenta resolverlo con pipeline! \n",
    "PyAyuda: Puedes probar con'question-answering' o 'summarization' si no se te ocurre nada! 😉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467e4aac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
