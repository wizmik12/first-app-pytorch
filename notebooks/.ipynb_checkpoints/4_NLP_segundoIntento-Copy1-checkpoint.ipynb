{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e16a9ce4",
   "metadata": {},
   "source": [
    "# 4. Procesamiento de Lenguaje Natural\n",
    "\n",
    "Otro de los campos de aplicaci√≥n para los que m√°s se utiliza PyTorch es para el Procesamiento de Lenguaje Natural (NLP), donde se ha convertido en una de las librer√≠as estrella para el dise√±o e implementaci√≥n de modelos de lenguaje sofisticados, por ejemplo, para traducci√≥n autom√°tica o generaci√≥n de texto. En este taller se muestran aspectos clave para comenzar tu recorrido pythonero en el mundo del NLP. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9030854",
   "metadata": {},
   "source": [
    "## Antes de comenzar...\n",
    "\n",
    "De nuevo cargamos la librer√≠a de Pytorch, y en este caso adem√°s *torchtext*, que contiene las funcionalidades necesarias para trabajar con texto con Pytorch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1c2d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "from torchinfo import summary\n",
    "from torchnlp import *\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ba5d7f",
   "metadata": {},
   "source": [
    "## Carga del Dataset AG_NEWS\n",
    "\n",
    "En este experimento utilizaremos el dataset AG_NEWS, que nos permitir√° llevar a cabo tareas de clasificaci√≥n de documentos en las categor√≠as contempladas por el dataset: world, sports, business, sci/tech. Este dataset es muy sencillo de cargar y utilizar, puesto que viene por defecto en la librer√≠a *torchtext*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4cbc380",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = torchtext.datasets.AG_NEWS(root='../data')\n",
    "classes = ['World', 'Sports', 'Business', 'Sci/Tech']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e3c7ed",
   "metadata": {},
   "source": [
    "## Tokenizaci√≥n del texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6a56fa",
   "metadata": {},
   "source": [
    "Cuando queremos abordar tareas de procesamiento de lenguaje natural, tenemos que tomar la decisi√≥n de qu√© m√≠nima unidad de representaci√≥n utilizar.  Podemos trabajar, por ejemplo, a nivel de caracter, a nivel de palabra, o a nivel de frase. Esta decisi√≥n suele venir tomada por diversas razones, como puede ser las caracter√≠sticas propias del dataset, el m√©todo en concreto que queramos aplicar, y por supuesto, la tarea final en cuesti√≥n. \n",
    "\n",
    "En nuestro caso, hemos decidido trabajar a nivel de palabra, una de las formas m√°s utilizadas, y que adem√°s nos permite abordar de forma sencilla la clasificaci√≥n a nivel de documento. Si lo razonamos, una idea intuitiva para realizar dicha clasificaci√≥n ser√≠a intentar identificar patrones/expresiones/relaciones claras a nivel de frase para determinar a qu√© categor√≠a pertenece un texto. \n",
    "\n",
    "En nuestro caso hemos usado el tokenizador *basic_english* porque nos permite un tratamiento sencillo del texto en ingl√©s a nivel de palabra, pero podr√≠amos importar tokenizadores propios, de otras librer√≠as como *Gensim* o *Spacy*, o incluso implementarlos nosotros. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a534d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ab6f00",
   "metadata": {},
   "source": [
    "Al usar la clase *Counter*, podemos detectar todos los tokens que se encuentran en nuestro dataset (lo que a partir de ahora ser√° nuestro vocabulario). Cada uno de estos tokens tiene asociada una cifra √∫nica. \n",
    "\n",
    "Finalmente almacenarlos en un objeto de la clase *colab*, encargada de almacenar y manejar vocabularios de un corpus. Con su m√©todo *stoi()* podemos recuperar la codificaci√≥n de las palabras del vocabulario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5888b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter()\n",
    "for (label, line) in train_dataset:\n",
    "    counter.update(tokenizer(line))\n",
    "vocab_ = torchtext.vocab.vocab(counter)\n",
    "\n",
    "vocab_size = len(vocab_)\n",
    "\n",
    "stoi = vocab_.get_stoi()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7165aad7",
   "metadata": {},
   "source": [
    "Veamos el resultado de tokenizar noticias del dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40abd66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "first token list:\n",
      "['wall', 'st', '.', 'bears', 'claw', 'back', 'into', 'the', 'black', '(', 'reuters', ')', 'reuters', '-', 'short-sellers', ',', 'wall', 'street', \"'\", 's', 'dwindling\\\\band', 'of', 'ultra-cynics', ',', 'are', 'seeing', 'green', 'again', '.']\n",
      "\n",
      "second token list:\n",
      "['carlyle', 'looks', 'toward', 'commercial', 'aerospace', '(', 'reuters', ')', 'reuters', '-', 'private', 'investment', 'firm', 'carlyle', 'group', ',', '\\\\which', 'has', 'a', 'reputation', 'for', 'making', 'well-timed', 'and', 'occasionally\\\\controversial', 'plays', 'in', 'the', 'defense', 'industry', ',', 'has', 'quietly', 'placed\\\\its', 'bets', 'on', 'another', 'part', 'of', 'the', 'market', '.']\n"
     ]
    }
   ],
   "source": [
    "train_dataset = list(train_dataset)\n",
    "test_dataset = list(test_dataset)\n",
    "\n",
    "\n",
    "first_sentence = train_dataset[0][1]\n",
    "second_sentence = train_dataset[1][1]\n",
    "\n",
    "f_tokens = tokenizer(first_sentence)\n",
    "s_tokens = tokenizer(second_sentence)\n",
    "\n",
    "print(f'\\nfirst token list:\\n{f_tokens}')\n",
    "print(f'\\nsecond token list:\\n{s_tokens}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8388ba8",
   "metadata": {},
   "source": [
    "## Codificaci√≥n del texto"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c1fedf",
   "metadata": {},
   "source": [
    "Para poder trabajar con entradas textuales en una red neuronal necesitamos una transformaci√≥n previa que nos permita obtener una codificaci√≥n num√©rica a partir del texto. A esta codificaci√≥n num√©rica la llamamos **embedding** y se realiza sobre el conjunto de tokens que forma la sentencia.  \n",
    "\n",
    "Podemos obtener una representaci√≥n num√©rica del texto asoci√°ndole una cifra num√©rica a cada token de la secuencia. De esta forma, tambi√©n podemos hacer la transformaci√≥n inversa y obtener un texto a partir de los tokens generados y manejados por la red neuronal internamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d3d991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x):\n",
    "    # print([vocab[s] for s in tokenizer(x)])\n",
    "    return [stoi[s] for s in tokenizer(x)]\n",
    "\n",
    "vec = encode(first_sentence) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632dc73b",
   "metadata": {},
   "source": [
    "### Ejemplo\n",
    "\n",
    "A continuaci√≥n vemos un ejemplo del resultado obtenido tras emplear el tokenizador. Partimos de la siguiente sentencia: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a939b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again. Sentencia\n"
     ]
    }
   ],
   "source": [
    "first_sentence = train_dataset[0][1]\n",
    "print(first_sentence, \"Sentencia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd76ee5f",
   "metadata": {},
   "source": [
    "Los tokens que se obtienen de dicha sentencia est√°n mostrados a continuaci√≥n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17d2008e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wall', 'st', '.', 'bears', 'claw', 'back', 'into', 'the', 'black', '(', 'reuters', ')', 'reuters', '-', 'short-sellers', ',', 'wall', 'street', \"'\", 's', 'dwindling\\\\band', 'of', 'ultra-cynics', ',', 'are', 'seeing', 'green', 'again', '.'] Tokens asociados a la sentencia\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer(first_sentence), \"Tokens asociados a la sentencia\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83bd53f",
   "metadata": {},
   "source": [
    "Y la codificaci√≥n de la sentencia finalmente es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5717518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 10, 12, 13, 14, 0, 15, 16, 17, 18, 19, 20, 14, 21, 22, 23, 24, 2] <- Embedding\n"
     ]
    }
   ],
   "source": [
    "vec = encode(first_sentence)\n",
    "print(vec, \"<- Embedding\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23509396",
   "metadata": {},
   "source": [
    "## Modelo de bolsa de palabras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0503eb",
   "metadata": {},
   "source": [
    "Para mostrar un ejemplo de uso de Pytorch para un modelo de lenguaje vamos a construir uno de los modelos m√°s sencillos, conocido como **bolsa de palabras**. Tal y como la propia definici√≥n indica, estos modelos consideran las secuencias de entrada como conjuntos de palabras. En funci√≥n de las palabras que forman una noticia, esta se clasifica en una o en otra clase. Es importante tener en cuenta que se trata de conjuntos de tokens que no consideran el orden original de dichos tokens en el texto. \n",
    "\n",
    "En nuestro caso, vamos a utilizar el conjunto de noticias que cargamos al principio del notebook para realizar un problema de **clasificaci√≥n de documentos** y clasificar las noticias en funci√≥n de su tem√°tica.\n",
    "\n",
    "Podemos definir una bolsa de palabras como un vector (o tensor) de ceros donde los tokens que aparecen en el texto toman valor distinto de 0 usando para ello la posici√≥n del vector). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "96a377ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentencia:\n",
      "Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\n",
      "\\Bolsa de palabras asociada:\n",
      "tensor([2., 1., 2.,  ..., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "def to_bow(text,bow_vocab_size=vocab_size):\n",
    "    res = torch.zeros(bow_vocab_size,dtype=torch.float32)\n",
    "    for i in encode(text):\n",
    "        if i<bow_vocab_size:\n",
    "            res[i] += 1\n",
    "    return res\n",
    "\n",
    "print(f\"Sentencia:\\n{train_dataset[0][1]}\")\n",
    "print(f\"\\Bolsa de palabras asociada:\\n{to_bow(train_dataset[0][1])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f66e14",
   "metadata": {},
   "source": [
    "> **Ejercicio 1**: ¬øQu√© significa el valor 2 en la primera posici√≥n del vector?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f1b424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2936d3ed",
   "metadata": {},
   "source": [
    "### Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede65aab",
   "metadata": {},
   "source": [
    "Ahora encapsulamos nuestros conjuntos de train y test, ya codificados anteriormente, en objetos DataLoader para proceder a entrenar el modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b7d19c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import numpy as np \n",
    "\n",
    "def bowify(b):\n",
    "    return (\n",
    "            torch.LongTensor([t[0]-1 for t in b]),\n",
    "            torch.stack([to_bow(t[1]) for t in b])\n",
    "    )\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, collate_fn=bowify, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, collate_fn=bowify, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bdd523",
   "metadata": {},
   "source": [
    "Es un modelo muy sencillo, por lo que nuestra red se basa en una capa Sequential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2bd4c027",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(torch.nn.Linear(vocab_size,4),torch.nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a4de94",
   "metadata": {},
   "source": [
    "Y una vez tenemos implementada la red, entrenamos el modelo de la forma que hemos venido haciendo a lo largo del taller. ¬°Ya somos expertos!. En este caso, hemos implementado el entrenamiento para una sola √©poca, puesto que los modelos de lenguaje son costosos computacionalmente, y este modelo adem√°s es sencillo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7af25c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(net,dataloader,lr=0.01,optimizer=None,loss_fn = torch.nn.NLLLoss(),epoch_size=None, report_freq=200):\n",
    "    optimizer = optimizer or torch.optim.Adam(net.parameters(),lr=lr)\n",
    "    net.train()\n",
    "    total_loss,acc,count,i = 0,0,0,0\n",
    "    for labels,features in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        out = net(features)\n",
    "        loss = loss_fn(out,labels) #cross_entropy(out,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss+=loss\n",
    "        _,predicted = torch.max(out,1)\n",
    "        acc+=(predicted==labels).sum()\n",
    "        count+=len(labels)\n",
    "        i+=1\n",
    "        if i%report_freq==0:\n",
    "            print(f\"{count}: acc={acc.item()/count}\")\n",
    "        if epoch_size and count>epoch_size:\n",
    "            break\n",
    "    return total_loss.item()/count, acc.item()/count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6748322",
   "metadata": {},
   "source": [
    "### ¬°A entrenar! üèãüèº‚Äç‚ôÄÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1937c806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200: acc=0.8071875\n",
      "6400: acc=0.83453125\n",
      "9600: acc=0.85125\n",
      "12800: acc=0.8615625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.02603057300104007, 0.8654717484008528)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_epoch(net,train_loader,epoch_size=15000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87341e78",
   "metadata": {},
   "source": [
    "# Pytorch Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f80dfcc",
   "metadata": {},
   "source": [
    "No podemos hablar de PyTorch y procesamiento de lenguaje natural sin mencionar la librer√≠a **transformers** de Hugging Faceü§ó.\n",
    "\n",
    "A pesar de las grandes ventajas que da Pytorch a la hora de implementar modelos para NLP, en proyectos grandes y con redes neuronales complejas lo que se suele hacer es combinar su uso con el de la librer√≠a **transformers**. Esta librer√≠a contiene implementaciones de PyTorch de modelos de lenguaje asentados y muy utilizados actualmente, as√≠ como modelos pre-entrenados que podemos cargar directamente para su uso, ¬°y mucho m√°s! \n",
    "\n",
    "Aunque puedes usar Transformers por s√≠ solo, una aplicaci√≥n normalmente requiere su combinaci√≥n con funcionalidades de la librer√≠a PyTorch, por ejemplo, para el uso de datasets y preprocesamiento de los datos. ¬°Podr√≠as aplicar todo lo aprendido durante este taller! \n",
    "\n",
    "Esta librer√≠a opera como una capa intermedia entre nuestra implementaci√≥n y la librer√≠a PyTorch, permitiendo entrenar y utilizar modelos sofisticados de procesamiento de lenguaje natural en cuesti√≥n de muy pocas l√≠neas de c√≥digo. Prueba de ello es su funcionalidad *pipeline* que se encarga de cargar autom√°ticamente todo lo necesario para ejecutar un modelo, para que √∫nicamente te preocupes de tu tarea final.\n",
    "\n",
    "### ¬°Veamos un ejemplo!\n",
    "Podemos usar *pipeline* con un modelo de clasificaci√≥n de sentimientos. Con tres l√≠neas hemos podido saber si un texto contiene connotaciones positivas o negativas. üò≥ü§Ø"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66bfd411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9984990358352661}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(\"sentiment-analysis\")\n",
    "classifier(\"I am super excited because I've been waiting for a Python Conference in Granada my whole life.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "313dddfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9980828762054443}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"I've been waiting for a Python Conference in Granada my whole life. Miguel and Andrea are really disgusting people.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03334d76",
   "metadata": {},
   "source": [
    "> **Ejercicio 2**: elige otro problema de procesamiento de lenguaje natural, e intenta resolverlo con pipeline! \n",
    "PyAyuda: Puedes probar con'question-answering' o 'summarization' si no se te ocurre nada! üòâ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "467e4aac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
