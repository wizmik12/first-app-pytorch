{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c02a868",
   "metadata": {},
   "source": [
    "# 4. Procesamiento de Lenguaje Natural"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647a6da7",
   "metadata": {},
   "source": [
    "## Antes de comenzar..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1c2d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchtext\n",
    "from torchinfo import summary\n",
    "from torchnlp import *\n",
    "from collections import Counter\n",
    "\n",
    "train_dataset, test_dataset = torchtext.datasets.AG_NEWS(root='../data')\n",
    "classes = ['World', 'Sports', 'Business', 'Sci/Tech']\n",
    "\n",
    "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')\n",
    "\n",
    "counter = Counter()\n",
    "for (label, line) in train_dataset:\n",
    "    counter.update(tokenizer(line))\n",
    "vocab_ = torchtext.vocab.vocab(counter)\n",
    "\n",
    "vocab_size = len(vocab_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675fd62f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5888b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = vocab_.get_stoi()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659160ee",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40abd66b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "first token list:\n",
      "['wall', 'st', '.', 'bears', 'claw', 'back', 'into', 'the', 'black', '(', 'reuters', ')', 'reuters', '-', 'short-sellers', ',', 'wall', 'street', \"'\", 's', 'dwindling\\\\band', 'of', 'ultra-cynics', ',', 'are', 'seeing', 'green', 'again', '.']\n",
      "\n",
      "second token list:\n",
      "['carlyle', 'looks', 'toward', 'commercial', 'aerospace', '(', 'reuters', ')', 'reuters', '-', 'private', 'investment', 'firm', 'carlyle', 'group', ',', '\\\\which', 'has', 'a', 'reputation', 'for', 'making', 'well-timed', 'and', 'occasionally\\\\controversial', 'plays', 'in', 'the', 'defense', 'industry', ',', 'has', 'quietly', 'placed\\\\its', 'bets', 'on', 'another', 'part', 'of', 'the', 'market', '.']\n"
     ]
    }
   ],
   "source": [
    "train_dataset = list(train_dataset)\n",
    "test_dataset = list(test_dataset)\n",
    "\n",
    "\n",
    "first_sentence = train_dataset[0][1]\n",
    "second_sentence = train_dataset[1][1]\n",
    "\n",
    "f_tokens = tokenizer(first_sentence)\n",
    "s_tokens = tokenizer(second_sentence)\n",
    "\n",
    "print(f'\\nfirst token list:\\n{f_tokens}')\n",
    "print(f'\\nsecond token list:\\n{s_tokens}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a66d7ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### TokenizaciÃ³n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d3d991b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(x):\n",
    "    # print([vocab[s] for s in tokenizer(x)])\n",
    "    return [stoi[s] for s in tokenizer(x)]\n",
    "\n",
    "vec = encode(first_sentence) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a939b3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 10, 12, 13, 14, 0, 15, 16, 17, 18, 19, 20, 14, 21, 22, 23, 24, 2]\n",
      "['wall', 'st', '.', 'bears', 'claw', 'back', 'into', 'the', 'black', '(', 'reuters', ')', 'reuters', '-', 'short-sellers', ',', 'wall', 'street', \"'\", 's', 'dwindling\\\\band', 'of', 'ultra-cynics', ',', 'are', 'seeing', 'green', 'again', '.']\n"
     ]
    }
   ],
   "source": [
    "first_sentence = train_dataset[0][1]\n",
    "print(first_sentence)\n",
    "vec = encode(first_sentence)\n",
    "print(vec)\n",
    "print(tokenizer(first_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c6474f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = Counter()\n",
    "for (label, line) in train_dataset:\n",
    "    counter.update(tokenizer(line))\n",
    "vocab = torchtext.vocab.Vocab(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "874a3a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Index lockup in 1st sentence:\n",
      "[[1395, 'wall'], [1409, 'st'], [225971, '.'], [399, 'bears'], [17, 'claw'], [4123, 'back'], [6637, 'into'], [203843, 'the'], [761, 'black'], [41106, '('], [19310, 'reuters'], [40787, ')'], [19310, 'reuters'], [39206, '-'], [2, 'short-sellers'], [165685, ','], [1395, 'wall'], [1581, 'street'], [32235, \"'\"], [61724, 's'], [1, 'dwindling\\\\band'], [97909, 'of'], [2, 'ultra-cynics'], [165685, ','], [9723, 'are'], [135, 'seeing'], [828, 'green'], [1758, 'again'], [225971, '.']]\n",
      "\n",
      "Index lockup in 2nd sentence:\n",
      "[[15, 'carlyle'], [600, 'looks'], [758, 'toward'], [490, 'commercial'], [124, 'aerospace'], [41106, '('], [19310, 'reuters'], [40787, ')'], [19310, 'reuters'], [39206, '-'], [696, 'private'], [809, 'investment'], [1776, 'firm'], [15, 'carlyle'], [4676, 'group'], [165685, ','], [5, '\\\\which'], [18945, 'has'], [110153, 'a'], [117, 'reputation'], [50186, 'for'], [1114, 'making'], [2, 'well-timed'], [68872, 'and'], [1, 'occasionally\\\\controversial'], [296, 'plays'], [95488, 'in'], [203843, 'the'], [1192, 'defense'], [2264, 'industry'], [165685, ','], [18945, 'has'], [140, 'quietly'], [1, 'placed\\\\its'], [66, 'bets'], [56529, 'on'], [2508, 'another'], [1636, 'part'], [97909, 'of'], [203843, 'the'], [3637, 'market'], [225971, '.']]\n"
     ]
    }
   ],
   "source": [
    "word_lookup = [list((vocab[w], w)) for w in f_tokens]\n",
    "print(f'\\nIndex lockup in 1st sentence:\\n{word_lookup}')\n",
    "\n",
    "word_lookup = [list((vocab[w], w)) for w in s_tokens]\n",
    "print(f'\\nIndex lockup in 2nd sentence:\\n{word_lookup}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ef1dd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(net,dataloader,lr=0.01,optimizer=None,loss_fn = torch.nn.NLLLoss(),epoch_size=None, report_freq=200):\n",
    "    optimizer = optimizer or torch.optim.Adam(net.parameters(),lr=lr)\n",
    "    net.train()\n",
    "    total_loss,acc,count,i = 0,0,0,0\n",
    "    for labels,features in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = net(features)\n",
    "\n",
    "        loss = loss_fn(out,labels) #cross_entropy(out,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss+=loss\n",
    "        _,predicted = torch.max(out,1)\n",
    "        acc+=(predicted==labels).sum()\n",
    "        count+=len(labels)\n",
    "        i+=1\n",
    "        if i%report_freq==0:\n",
    "            print(f\"{count}: acc={acc.item()/count}\")\n",
    "        if epoch_size and count>epoch_size:\n",
    "            break\n",
    "    return total_loss.item()/count, acc.item()/count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23509396",
   "metadata": {},
   "source": [
    "# bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96a377ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample text:\n",
      "Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\n",
      "\n",
      "BoW vector:\n",
      "tensor([2., 1., 2.,  ..., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "def to_bow(text,bow_vocab_size=vocab_size):\n",
    "    res = torch.zeros(bow_vocab_size,dtype=torch.float32)\n",
    "    for i in encode(text):\n",
    "        if i<bow_vocab_size:\n",
    "            res[i] += 1\n",
    "    return res\n",
    "\n",
    "print(f\"sample text:\\n{train_dataset[0][1]}\")\n",
    "print(f\"\\nBoW vector:\\n{to_bow(train_dataset[0][1])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b7d19c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import numpy as np \n",
    "\n",
    "# this collate function gets list of batch_size tuples, and needs to \n",
    "# return a pair of label-feature tensors for the whole minibatch\n",
    "def bowify(b):\n",
    "    return (\n",
    "            torch.LongTensor([t[0]-1 for t in b]),\n",
    "            torch.stack([to_bow(t[1]) for t in b])\n",
    "    )\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, collate_fn=bowify, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, collate_fn=bowify, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bd4c027",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(torch.nn.Linear(vocab_size,4),torch.nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7af25c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(net,dataloader,lr=0.01,optimizer=None,loss_fn = torch.nn.NLLLoss(),epoch_size=None, report_freq=200):\n",
    "    optimizer = optimizer or torch.optim.Adam(net.parameters(),lr=lr)\n",
    "    net.train()\n",
    "    total_loss,acc,count,i = 0,0,0,0\n",
    "    for labels,features in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        out = net(features)\n",
    "        loss = loss_fn(out,labels) #cross_entropy(out,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss+=loss\n",
    "        _,predicted = torch.max(out,1)\n",
    "        acc+=(predicted==labels).sum()\n",
    "        count+=len(labels)\n",
    "        i+=1\n",
    "        if i%report_freq==0:\n",
    "            print(f\"{count}: acc={acc.item()/count}\")\n",
    "        if epoch_size and count>epoch_size:\n",
    "            break\n",
    "    return total_loss.item()/count, acc.item()/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1937c806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200: acc=0.8009375\n",
      "6400: acc=0.83609375\n",
      "9600: acc=0.8535416666666666\n",
      "12800: acc=0.861484375\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.02570772069349472, 0.8650053304904051)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_epoch(net,train_loader,epoch_size=15000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87341e78",
   "metadata": {},
   "source": [
    "# embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d0cb63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6537b792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padify(b):\n",
    "    # b is the list of tuples of length batch_size\n",
    "    #   - first element of a tuple = label, \n",
    "    #   - second = feature (text sequence)\n",
    "    # build vectorized sequence\n",
    "    v = [encode(x[1]) for x in b]\n",
    "    # first, compute max length of a sequence in this minibatch\n",
    "    l = max(map(len,v))\n",
    "    return ( # tuple of two tensors - labels and features\n",
    "        torch.LongTensor([t[0]-1 for t in b]),\n",
    "        torch.stack([torch.nn.functional.pad(torch.tensor(t),(0,l-len(t)),mode='constant',value=0) for t in v])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "465d3345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Sentence in dataset:\n",
      "Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\n",
      "Length: 144\n",
      "\n",
      "Second Sentence in dataset:\n",
      "Carlyle Looks Toward Commercial Aerospace (Reuters) Reuters - Private investment firm Carlyle Group,\\which has a reputation for making well-timed and occasionally\\controversial plays in the defense industry, has quietly placed\\its bets on another part of the market.\n",
      "Length:  266\n"
     ]
    }
   ],
   "source": [
    "first_sentence = train_dataset[0][1]\n",
    "second_sentence = train_dataset[1][1]\n",
    "\n",
    "f_tokens = encode(first_sentence)\n",
    "s_tokens = encode(second_sentence)\n",
    "\n",
    "print(f'First Sentence in dataset:\\n{first_sentence}')\n",
    "print(\"Length:\", len(train_dataset[0][1]))\n",
    "print(f'\\nSecond Sentence in dataset:\\n{second_sentence}')\n",
    "print(\"Length: \", len(train_dataset[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1e2dd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: tensor([[    0,     1,     2,  ...,     0,     0,     0],\n",
      "        [   25,    26,    27,  ...,     0,     0,     0],\n",
      "        [   54,    41,    55,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [36336,   809,  2615,  ...,     0,     0,     0],\n",
      "        [  924,    16,    17,  ...,     0,     0,     0],\n",
      "        [ 7836,   892,  6107,  ...,     0,     0,     0]])\n",
      "\n",
      "length of first sentence: 29\n",
      "length of second sentence: 42\n",
      "size of features: torch.Size([120000, 207])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "labels, features = padify(train_dataset)  \n",
    "print(f'features: {features}')\n",
    "\n",
    "print(f'\\nlength of first sentence: {len(f_tokens)}')\n",
    "print(f'length of second sentence: {len(s_tokens)}')\n",
    "print(f'size of features: {features.size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d51fa682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(95809)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b045b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbedClassifier(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embed_dim)\n",
    "        self.fc = torch.nn.Linear(embed_dim, num_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = torch.mean(x,dim=1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "11af40ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, collate_fn=padify, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ef238c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c54336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3233c60f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-547.582527281746, 0.25297619047619047)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = EmbedClassifier(225971,8,len(classes)).to(device)\n",
    "train_epoch(net,train_loader, lr=1, epoch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d4189d",
   "metadata": {},
   "source": [
    "### rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7387d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNClassifier(torch.nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_class):\n",
    "        super().__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = torch.nn.Embedding(vocab_size, embed_dim)\n",
    "        self.rnn = torch.nn.RNN(embed_dim,hidden_dim,batch_first=True)\n",
    "        self.fc = torch.nn.Linear(hidden_dim, num_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = self.embedding(x)\n",
    "        x,h = self.rnn(x)\n",
    "        return self.fc(x.mean(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ec482a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68555ba3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a885fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b6d34e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901decd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, collate_fn=padify, shuffle=True)\n",
    "net = RNNClassifier(225971+1,64,32,len(classes)).to(device)\n",
    "train_epoch(net,train_loader, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05eba929",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, collate_fn=padify, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f726a318",
   "metadata": {},
   "outputs": [],
   "source": [
    "net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (target, data) in enumerate(test_loader):\n",
    "        \n",
    "        word_lookup = [vocab.get_itos()[w] for w in data[batch_idx]]\n",
    "        unknow_vals = {'<unk>'}\n",
    "        word_lookup = [ele for ele in word_lookup if ele not in unknow_vals]\n",
    "        print('Input text:\\n {}\\n'.format(word_lookup))\n",
    "        \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        pred = net(data)\n",
    "        print(torch.argmax(pred[batch_idx]))\n",
    "        print(\"Actual:\\nvalue={}, class_name= {}\\n\".format(target[batch_idx], classes[target[batch_idx]]))\n",
    "        print(\"Predicted:\\nvalue={}, class_name= {}\\n\".format(pred[0].argmax(0),classes[pred[0].argmax(0)]))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53939516",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torchtext.vocab.Vocab(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b726a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a3de36",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.get_itos()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
