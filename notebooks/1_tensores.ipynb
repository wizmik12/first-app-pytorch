{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfcd4a20",
   "metadata": {},
   "source": [
    "## Pytorch Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f40c84f",
   "metadata": {},
   "source": [
    "En este notebook aprenderemos sobre los tensores de Pytorch. Son muy útiles ya que es donde guarda la información Pytorch, por lo tanto, deberemos saber manejarlos. Al final de este notebook sabrás como maneja la información el framework Pytorch y también como manejar, manipular y crear estos datos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4d25df",
   "metadata": {},
   "source": [
    "### Crear nuevos tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac0d32f",
   "metadata": {},
   "source": [
    "Pytorch maneja y guarda la información en los llamados **tensores** de Pytorch. Los tensores son una generalización de los vectores y matrices a arrays multidimensionales. Operar con tensores de Pytorch es muy similar a operar con tensores de numpy. De esta forma, veremos que muchas operaciones o formas de trabajar se pueden realizar de la misma manera aquí. La documentación está en este [link](https://pytorch.org/docs/stable/tensors.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c4eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # Importamos el módulo de Pytorch\n",
    "ones = torch.ones(5) # Creamos un vector de 5 componentes cuyo valor es '1'\n",
    "ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f943799f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = torch.zeros((5,5)) # Un vector/matriz de '0' puede ser una forma adecuada de inicialización\n",
    "print(\"Matriz de ceros: \\n\", zeros)\n",
    "\n",
    "# Construimos una matriz por columnas a partir de esta matriz de ceros\n",
    "for i in range(len(zeros)):\n",
    "    zeros[:,i] = i + 1\n",
    "\n",
    "print(\"Nueva matriz: \\n\", zeros)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1396310",
   "metadata": {},
   "source": [
    "También podemos crear un tensor de Pytorch a partir de una lista (o de un array de numpy):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5ecebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ = [1.0, 3.0, 5.0, 2.0, 9.0, 0.0]\n",
    "tensor = torch.tensor(list_)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5256edd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ = [[1.0, 3.0, 5.0], [2.0, 9.0, 0.0]] # Podemos añadirle dimensiones\n",
    "tensor = torch.tensor(list_)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cef557",
   "metadata": {},
   "source": [
    "**Ejercicio:** Define un tensor en Pytorch que represente una matriz de tamaño 6x6 cuyos elementos vayan de menor a mayor por filas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d865dd6e",
   "metadata": {},
   "source": [
    "### Indexación de tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a05ae0",
   "metadata": {},
   "source": [
    "Podemos usar la misma indexación que en Numpy. Esto será útil para extraer subtensores que nos serán útiles para entrenar o comprobar información de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20c9235",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_list = torch.tensor((list(range(6))))\n",
    "some_list[:]     # <1>\n",
    "some_list[1:4]   # <2>\n",
    "some_list[1:]    # <3>\n",
    "some_list[:4]    # <4>\n",
    "some_list[:-1]   # <5>\n",
    "some_list[1:4:2] # <6>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba49d81",
   "metadata": {},
   "source": [
    "**Ejercicio 2:** Transforma el tensor del ejercicio anterior. Recórrelo desde el final hacia delante de 2 en 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8918ca2",
   "metadata": {},
   "source": [
    "### Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac300737",
   "metadata": {},
   "source": [
    "Podemos operar con tensores aunque no tengan la misma dimensión. Podemos sumar un número a una matriz o multiplicar una matriz por un vector. Primero vemos la multiplicación de dos matrices del mismo tamaño, se efectúa elemento a elemento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd932e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = torch.tensor([[1, 2], [3, 4]])\n",
    "matrix2 = torch.tensor([[5, 6], [7, 8]])\n",
    "matrix * matrix2 # producto elemento a elemento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635a552a",
   "metadata": {},
   "source": [
    "También podemos hacer el producto matricial de estas dos matrices (vivan las matemáticas y el álgebra lineal!!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc2c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mm(matrix, matrix2) # producto matricial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6232cd",
   "metadata": {},
   "source": [
    "Por último vemos que podemos multiplicar un vector y una matriz, en este caso se hace también elemento a elemento, por columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72f2630",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = torch.tensor([1, 2]) # producto elemento a elemento en una dimension\n",
    "vector = vector.unsqueeze(-1)\n",
    "matrix * vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d00a09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix.shape, vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ea6fba",
   "metadata": {},
   "source": [
    "Si cambiamos las dimensiones del vector podemos hacer la operación por filas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d3ef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix * vector.view(1, 2) # Usamos view para hacer un 'reshape'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a1cc57",
   "metadata": {},
   "source": [
    "**Ejercicio 3:** A la matriz del ejercicio anterior que debería tener dimensión 3x3, multiplícale x2 a las primera fila, x3 a la segundo y x10 a la tercera."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861e644b",
   "metadata": {},
   "source": [
    "### Tipos de elementos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b959e2",
   "metadata": {},
   "source": [
    "En Pytorch tenemos distintos tipos de elementos para representar: enteros, punto flotantes, etc.\n",
    "En el caso de las redes neuronales, se suele usar **float32**, tiene menos precisión que 64-bit pero ganamos en memoria sin un fuerte impacto en la precisión del modelo. Pytorch espera que el indexado se haga con tensores **int64**. Además para indicar si algo está o no presente (booleano) se utilizará el tipo **bool**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21e4218",
   "metadata": {},
   "source": [
    "- torch.float32 o torch.float\n",
    "- torch.float64 o torch.double\n",
    "- torch.float16 o torch.half\n",
    "- torch.int8\n",
    "- torch.uint8\n",
    "- torch.int16 o torch.short\n",
    "- torch.int32 o torch.int\n",
    "- torch.int64 o torch.long\n",
    "- torch.bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d85c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector1 = torch.tensor([1, 1, 1])\n",
    "vector2 = torch.tensor([1.0, 1.0, 1.0])\n",
    "vector1.dtype, vector2.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8172e635",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector1 = torch.tensor([1, 1, 1], dtype=torch.float64)\n",
    "vector1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cc5458",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector1 = torch.tensor([1, 1, 1], dtype=torch.bool)\n",
    "vector1, vector1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e35abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_vector = torch.randn(3, 3).to(torch.double)\n",
    "random_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d34c6c",
   "metadata": {},
   "source": [
    "**Ejercicio 4:** Crea dos matriz randoms M1 y M2 de la misma dimensión que la resultante del ejercicio anterior, y construye una nueva matriz booleana donde el elemento sea True si el elemento correspondiente en las dos matrices random se cumple M1 > M2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5e2bba",
   "metadata": {},
   "source": [
    "### Copia de tensores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf20535c",
   "metadata": {},
   "source": [
    "Los vectores se pasan por referencia lo cual indica, que la memoria del nuevo vector está en el mismo lugar que el antiguo. Por lo cual modificar el nuevo vector modificará el antiguo. Mucho cuidado con esto!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d9954e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector1 = torch.tensor([1, 2])\n",
    "vector2 = vector1\n",
    "vector2[0] = 0\n",
    "vector1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b762206a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector1 = torch.tensor([1, 2])\n",
    "vector2 = vector1.clone()\n",
    "vector2[0] = 0\n",
    "vector1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c1025ec",
   "metadata": {},
   "source": [
    "### Tensor API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695ff626",
   "metadata": {},
   "source": [
    "Vamos a ver las distintas operaciones que se pueden hacer con tensores. La gran mayoría está disponible en el módulo de torch por lo que pueden ser llamadas como métodos de un objeto tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa680db",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(3, 4)\n",
    "a_t = torch.transpose(a, 0, 1) # damos las dimensiones que queremos intercambiar\n",
    "a.shape, a_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b8aaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(3, 4)\n",
    "a_t = a.transpose(0,1) # usamos el método del vector (pueden usarse indistinguiblemente)\n",
    "a.shape, a_t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be9c626",
   "metadata": {},
   "source": [
    "**Ejercicio 5:** Crea una matriz random de 5 x 5. Construye a partir de ella otro tensor que sea de tamaño 5 x 5 x 3, donde en la tercera dimensión se contenga la matriz de la primera dimensión pero multiplicada x2 y x3. Por último, intercambia la última dimensión con la primera.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810e3238",
   "metadata": {},
   "source": [
    "### Guardar los tensores en CPU y GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29db4e2",
   "metadata": {},
   "source": [
    "Una de las ventajasde Pytorch es que cuenta con aceleración en GPU. Tenemos que tener cuidado ya que los tensores se pueden alojar en la memoria de la cpu o de la gpu. Para operar con ellos se deben encontrar en la misma memoria. Cuando usemos redes neuronales será conveniente que se encuentren en la gpu para poder disfrutar del Deep Learning en su máxima expresión!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6e5f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_vector = torch.tensor([3, 4], device = 'cpu')\n",
    "gpu_vector = torch.tensor([3, 4], device = 'cuda')\n",
    "cpu_vector, gpu_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39679dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_vector.to(device='cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1559c299",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_vector.cpu(), cpu_vector.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f8439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_vector.to(device = 'cuda', dtype = torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c029698",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_vector + gpu_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aeed71b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_sum = cpu_vector.cuda() + gpu_vector\n",
    "gpu_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98548cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_sum.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513f5800",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_sum.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54437b97",
   "metadata": {},
   "source": [
    "### Avanzado: Contiguos y dónde están"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "553fb258",
   "metadata": {},
   "source": [
    "Los tensores contiguos son aquellos tensores que pueden ser recorridos sin dar saltos en memoria. Esto ayuda a la eficiencia de los algoritmos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3bd07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(3, 2)\n",
    "a_t = a.transpose(0, 1)\n",
    "a.is_contiguous(), a_t.is_contiguous()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f9927df",
   "metadata": {},
   "source": [
    "Algunas funciones necesitan que el vector sea contiguo. Para ello podemos utilizar el método .contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f203a371",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_t.view(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36c7dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_t.contiguous().view(3, 2).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
