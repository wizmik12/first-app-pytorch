{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71054c62",
   "metadata": {},
   "source": [
    "# 3. Clasificación de imágenes con Redes Neuronales"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56972851",
   "metadata": {},
   "source": [
    "En este notebook, veremos como llevar a cabo un proyecto de clasificación de imágenes usando redes neuronales. Para ello, haremos un ejemplo de imágenes de satélite. Al final del notebook, sabrás qué arquitectura se usan para clasificación de imágenes, y cómo diseñarla y entrenarla desde 0 o coger una ya preentrenada. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91345de",
   "metadata": {},
   "source": [
    "## Descargamos el dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8083618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.manual_seed(123)\n",
    "\n",
    "from torchvision import datasets\n",
    "\n",
    "data_path = '../EuroSAT/'\n",
    "eurosat = datasets.EuroSAT(data_path, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452bc7aa",
   "metadata": {},
   "source": [
    "Tenemos muchos datasets que podemos descargar directamente desde Pytorch. Incluye reconocimiento de objetos, dígitos, plantas, cáncer, etc. Podemos ver la documentación en: https://pytorch.org/vision/stable/datasets.html\n",
    "y abajo desplegamos la lista de datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb24f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(datasets) # En Pytorch tenemos para probar multitud de datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb6ba36",
   "metadata": {},
   "source": [
    "Vemos un ejemplo de las 10 clases que componen este dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c77a35b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class_names = eurosat.classes\n",
    "\n",
    "fig = plt.figure(figsize=(16,6))\n",
    "num_classes = 10\n",
    "for i in range(num_classes):\n",
    "    ax = fig.add_subplot(2, 5, 1 + i, xticks=[], yticks=[])\n",
    "    ax.set_title(class_names[i])\n",
    "    img = next(img for img, label in eurosat if label == i)\n",
    "    plt.imshow(img)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d823862",
   "metadata": {},
   "outputs": [],
   "source": [
    "eurosat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bec3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(eurosat).__mro__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050509bf",
   "metadata": {},
   "source": [
    "Vemos que el dataset EUROSAT es una subclase de *torch.utils.data.dataset.Dataset*. Pytorch usa esta clase para trabajar con datasets. Se caracteriza por tener dos métodos: *\\_\\_len\\_\\_* y *\\_\\_getitem\\_\\_*.\n",
    "\n",
    "- *\\_\\_len\\_\\_* nos dice el tamaño del dataset.\n",
    "- *\\_\\_getitem\\_\\_* nos permite indexar elementos del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9e81bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(eurosat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df2d1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = eurosat[100]\n",
    "print(img, label, class_names[label])\n",
    "\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde89041",
   "metadata": {},
   "source": [
    "Los objetos del dataset son imágenes PIL. Para poder trabajar con nuestras redes neuronales en Pytorch necesitamos convertirlas en tensores! Esto se consigue con la función *torchvision.transforms.ToTensor()*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cd2914",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "to_tensor = transforms.ToTensor()\n",
    "img_t = to_tensor(img)\n",
    "img_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc7fed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_eurosat = datasets.EuroSAT(data_path, download=False,\n",
    "                         transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb806a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_t.permute(1, 2, 0))  # <1>\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ef2c05",
   "metadata": {},
   "source": [
    "### Dividimos en train-test y normalizamos!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dd25b0",
   "metadata": {},
   "source": [
    "En un proyecto de machine learning, solemos dividir los datos en train, validación y test. De tal modo, que aprendemos los patrones con el conjunto de train y vemos como de bueno es el modelo con un conjunto de validación que no ha sido usado para entrenar. Por último se le pasa un test independiente para ver su capacidad de generalización y posterior aplicabilidad. En este caso, dividiremos nuestros datos en train-test. Nos quedamos con un 80% de los datos para entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2a84e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "indices = list(range(len(eurosat)))\n",
    "random.seed(310) \n",
    "random.shuffle(indices)\n",
    "\n",
    "train_size = int(0.8 * len(eurosat))\n",
    "train_dataset_split = torch.utils.data.Subset(tensor_eurosat, indices[:train_size])\n",
    "\n",
    "imgs = torch.stack([img_t for img_t, _ in train_dataset_split], dim=3)\n",
    "imgs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991ac32a",
   "metadata": {},
   "source": [
    "Es importante normalizar los datos, para ellos le quitamos la media a cada canal y dividimos por la desviación típica. Esto lo haremos con la función *transforms.Normalize*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b15a020",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs.view(3, -1).mean(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a256fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs.view(3, -1).std(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891f7392",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_eurosat = datasets.EuroSAT(\n",
    "    data_path,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.3452, 0.3810, 0.4083),\n",
    "                             (0.2036, 0.1367, 0.1150))\n",
    "    ]))\n",
    "\n",
    "eurosat_train = torch.utils.data.Subset(transformed_eurosat, indices[:train_size])\n",
    "eurosat_val = torch.utils.data.Subset(transformed_eurosat, indices[train_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40133b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_t, _ = eurosat_train[120]\n",
    "\n",
    "plt.imshow(img_t.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50984b5d",
   "metadata": {},
   "source": [
    "Podemos recuperar la imagen original invirtiendo la normalización previamente usada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b14b905",
   "metadata": {},
   "outputs": [],
   "source": [
    "invTrans = transforms.Compose([ transforms.Normalize(mean = [ 0., 0., 0. ],\n",
    "                                                     std = [ 1/0.2036, 1/0.1367, 1/0.1150 ]),\n",
    "                                transforms.Normalize(mean = [ -0.2036, -0.1367, -0.1150 ],\n",
    "                                                     std = [ 1., 1., 1. ]),\n",
    "                               ])\n",
    "\n",
    "inv_tensor = invTrans(img_t)\n",
    "\n",
    "plt.imshow(inv_tensor.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec124855",
   "metadata": {},
   "source": [
    "## Mi primera red convolucional: LeNet (1989)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15ee2c3",
   "metadata": {},
   "source": [
    "La primera red convolucional que vamos a implementar se llama LeNet. Fue de las primeras en existir y es muy simple. Podemos definirla de forma sencilla en pocas líneas.\n",
    "\n",
    "Se compone de capas convolucionales con activaciones de tangente hiperbólica seguidas de average pooling. Por último tiene un clasificador no lineal. Podemos ver la primera parte de la red neuronal con convoluciones como el extractor de características de la imagen. Las convoluciones nos extraen información local de cada píxel. Con el pooling logramos reducir la dimensión de la imagen siendo más tratable. Las primeras capas almacenan información más local de la imagen mientras que las más profundas tienen características más globales, esto es debido a la composición de distintas funciones no lineales que agrupa información de distintos puntos de la imagen. Luego el clasificador trata de predecir las probabilidades asociadas a cada clase. En este caso al tener más de dos clases se usa una capa softmax.\n",
    "\n",
    "* Pooling: Operación mediante la cual se reduce el tamaño de los datos. Se suele reemplazar cada cuadrícula de cierto tamaño, por el máximo o la media de ella. Por ejemplo, en Lenet, cada cuadrícula de 2x2 es reemplazada por la media de los 4 números.\n",
    "\n",
    "* Convolución: Es una operación mediante la cual se aplica una operación lineal a cada píxel, donde los pesos solo influyen en un vecindario (es muy poco práctico aplicar una operación lineal que dependa de TODOS los píxeles!, sobreajustaría). En este caso, consigue aprender información local de la imagen como aristas, esquinas, etc.\n",
    "\n",
    "* SoftMax: Esta capa convierte un vector de números reales en números entre 0 y 1. Podemos entender que esta capa nos devuelve una distribución de probabilidad para las clases. \n",
    "\n",
    "$$ SoftMax(\\mathbf{x})_i = \\frac{e^{\\mathbf{x_i}}}{\\sum^D_{j=1}e^{\\mathbf{x_j}}}$$\n",
    "\n",
    "*torch.nn* contiene capas que nos serán útiles para las redes neuronales. Además *torch.nn.F* contiene funciones que son propias también de las redes neuronales y son usadas en estas capas.\n",
    "\n",
    "Las redes neuronales heredan de la clase *nn.Module* y en el *\\__init__* podemos definir las distintas capas que usaremos. Es muy importante el método forward. Ahí definimos cómo será el flow de la red, es decir, qué capas y en que orden se aplicarán sobre los datos. Cuando apliquemos la red sobre unos datos se ejecutará este método. En este caso devolvemos logits sin normalizar y probabilidades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb01862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "class LeNet5(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "        self.feature_extractor = nn.Sequential(            \n",
    "            nn.Conv2d(in_channels=3, out_channels=6, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=6, out_channels=36, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2),\n",
    "            nn.Conv2d(in_channels=36, out_channels=64, kernel_size=5, stride=1),\n",
    "            nn.Tanh(),\n",
    "            nn.AvgPool2d(kernel_size=2)\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(in_features=1024, out_features=128),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(in_features=128, out_features=n_classes),\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.feature_extractor(x) # Se extraen los rasgos automáticamente\n",
    "        x = torch.flatten(x, 1) # Ponemos el volumen como un vector\n",
    "        logits = self.classifier(x) # Se usa una red neuronal para clasificar los rasgos\n",
    "        probs = F.softmax(logits, dim=1) # Calculamos la probabilidad\n",
    "        return logits, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f535778",
   "metadata": {},
   "source": [
    "En Pytorch tenemos que disponer los datos en la clase Dataset, en este caso los datos de torch vision vienen ya directamente en este formato. Para poder trabajar con ellos en batches debemos cargarlos en un DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c1a6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(eurosat_train, batch_size=64,\n",
    "                                           shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(eurosat_val, batch_size=64,\n",
    "                                         shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341ec52a",
   "metadata": {},
   "source": [
    "Definimos el modelo y definimos el optimizador, la pérdida el bucle de entrenamiento, ... tal y como habíamos visto en el notebook anterior. Qué simplicidad!! Pytorch te amo!!\n",
    "\n",
    "En este caso no podemos usar la misma función de pérdida que en regresión. La función de pérdida depende de cada problema. En clasificación se suele utilizar la entropía cruzada. Esta función se define como:\n",
    "\n",
    "$$CE(y, y') = \\sum_{c=1}^C y_{o,c} log(y'_{o,c})$$\n",
    "\n",
    "Siendo $y_{o, c}$ los datos que tienen como clase real la clase $c$ y  $log(y'_{o,c})$ la probabilidad correspondiente asignada por la red neuronal. Esta pérdida busca separar las clases lo máximo posible, queriendo que la probabilidad se lo más alta en la clase auténtica y lo más baja en las clase que no lo son. De hecho penaliza bastante (por el logaritmo) los fallos estrepitosos, considerando también el suavizado de probabilidades en casos difíciles.\n",
    "\n",
    "Pytorch espera que la entrada de la función de pérdida sea las puntuaciones antes de la capa softmax. Podemos aplicar esta capa para predecir posteriormente y tener interpretabilidad del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1b7f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet5_model = LeNet5(n_classes=10)  #  <2>\n",
    "optimizer = torch.optim.SGD(lenet5_model.parameters(), lr=1e-2)  #  <3>\n",
    "loss_fn = nn.CrossEntropyLoss()  #  <4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4bd426",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (torch.device('cuda') if torch.cuda.is_available()\n",
    "          else torch.device('cpu'))\n",
    "print(f\"Training on device {device}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5be42af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    model = model.to(device=device)\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        model.train() # Modo train\n",
    "        \n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device)  # <1>\n",
    "            labels = labels.to(device=device)\n",
    "            logits, _ = model(imgs)\n",
    "            loss = loss_fn(logits, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))\n",
    "            validate(model, train_loader, val_loader, device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2fa9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, train_loader, val_loader, device):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        model.eval() # Ponemos nuestrom modelo en modo evaluación\n",
    "\n",
    "        with torch.no_grad():  # <1>\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device=device)\n",
    "                labels = labels.to(device=device)\n",
    "                outputs, _ = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
    "                total += labels.shape[0]  # <3>\n",
    "                correct += int((predicted == labels).sum())  # <4>\n",
    "\n",
    "        print(\"Accuracy in {}: {:.2f}\".format(name , correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8871408e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet_model_trained = training_loop(\n",
    "    n_epochs = 100,\n",
    "    optimizer = optimizer,\n",
    "    model = lenet5_model,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdc04026",
   "metadata": {},
   "source": [
    "Cada vez que usemos nuestra red no vamos a volverla a entrenar!! Por ello podemos guardar los pesos para cargarlos posteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee827bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "model_path = \"../models/\"\n",
    "if not os.path.exists(model_path):\n",
    "    os.mkdir(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b17fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(lenet_model_trained.state_dict(), model_path + 'lenet5.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8494033a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = LeNet5(n_classes=10)  \n",
    "loaded_model.load_state_dict(torch.load(model_path\n",
    "                                        + 'lenet5.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890e063a",
   "metadata": {},
   "source": [
    "**Ejercicio 1:** Prueba a modificar la red: hacerla más profunda, más ancha, un clasificador más complejo,... ¿cómo altera esto el proceso de entrenamiento?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e91f040",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af70bf9a",
   "metadata": {},
   "source": [
    "## Pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88177640",
   "metadata": {},
   "source": [
    "Una cosa muy interesante de Pytorch es que tenemos modelos preentrenados muy potentes que solo tendremos que reentrenar en nuestros datos. En este ejemplo, usamos la efficientnet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc692f3c",
   "metadata": {},
   "source": [
    "https://pytorch.org/vision/stable/models.html#semantic-segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96074be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "efficientnet = torchvision.models.efficientnet_b0(weights=\"IMAGENET1K_V1\")\n",
    "print(efficientnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd75039",
   "metadata": {},
   "source": [
    "Tenemos que modificar el clasificador para que se adapte a nuestro número de clases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b022bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet.classifier[1] = nn.Linear(in_features = 1280, out_features = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fe4567",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    model = model.to(device=device)\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        model.train() # Modo train\n",
    "        \n",
    "        for imgs, labels in train_loader:\n",
    "            imgs = imgs.to(device=device)  # <1>\n",
    "            labels = labels.to(device=device)\n",
    "            logits = model(imgs)\n",
    "            loss = loss_fn(logits, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "\n",
    "        if epoch == 1 or epoch % 2 == 0:\n",
    "            print('{} Epoch {}, Training loss {}'.format(\n",
    "                datetime.datetime.now(), epoch,\n",
    "                loss_train / len(train_loader)))\n",
    "            validate(model, train_loader, val_loader, device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235148fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, train_loader, val_loader, device):\n",
    "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        model.eval() # Ponemos nuestrom modelo en modo evaluación\n",
    "\n",
    "        with torch.no_grad():  # <1>\n",
    "            for imgs, labels in loader:\n",
    "                imgs = imgs.to(device=device)\n",
    "                labels = labels.to(device=device)\n",
    "                outputs = model(imgs)\n",
    "                _, predicted = torch.max(outputs, dim=1) # <2>\n",
    "                total += labels.shape[0]  # <3>\n",
    "                correct += int((predicted == labels).sum())  # <4>\n",
    "\n",
    "        print(\"Accuracy in {}: {:.2f}\".format(name , correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2661a16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(efficientnet.parameters(), lr=1e-3) \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "efficientnet_trained = training_loop(\n",
    "    n_epochs = 20,\n",
    "    optimizer = optimizer,\n",
    "    model = efficientnet,\n",
    "    loss_fn = loss_fn,\n",
    "    train_loader = train_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff472d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(efficientnet_trained.state_dict(), model_path + 'efficientnet.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8ffa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e10bcd",
   "metadata": {},
   "source": [
    "**Ejercicio 2:** Examina las redes disponibles en torchvision y prueba otra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001e963a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
